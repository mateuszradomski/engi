

IMPLEMENTACJA


W tym rozdziale opisana jest implementacja uruchomienia algorytmów mnożenia macierzy rzadkiej przez wektor na procesorze graficznym. Pierwszy podrozdział omawia opracowany sposób na komunikację z procesorem graficznym przy wykorzystaniu interfejsu _Vulkan_. Drugi przedstawia sposób przechowywania danego formatu macierzy rzadkiej, konwersji na ten format oraz shader obliczeniowy, którego zadaniem jest obliczenie wyniku mnożenia macierz - wektor dla tego formatu.


Komunikacja z procesorem graficznym

Aby rozpocząć komunikację z procesorem graficznym należy stworzyć obiekty skonfigurowane w taki sposób, w jaki zamierzamy ich używać. Inicjalizacja stanu początkowego w interfejsie Vulkan sprowadza się do stworzenia instancji, wybrania fizycznego urządzenia oraz na jego podstawie stworzenia urządzenia logicznego, stworzenia puli zasobów, z których korzystać będą obiekty komend i kwerend. Podczas tworzenia instancji użytkownik ma możliwość podania tablicy z warstwami, które mają zostać włączone oraz rozszerzeń, które mają zostać dodane do danej instancji. Warstwy to rozwiązanie problemu debugowania programów napisanych przy użyciu interfejsu _Vulkan_. Ponieważ sterownik graficzny nie sprawdza poprawności przesłanych do niego danych, znajdowanie źródeł błędów jest o wiele trudniejsze. Rozwiązaniem tego problemu są warstwy, czyli dodatkowy kod wykonywany dookoła wywołania funkcji. Takie podejście można opisać jako wzorzec projektowy dekorator. Istnieje wiele warstw, które pełnią różne funkcje, przykładowo dodając warstwę zapisującą kiedy dana funkcja została wywołana, możemy stworzyć graf wywołań w danym programie. Najbardziej pomocną warstwą podczas tworzenia aplikacji od nowa jest warstwa walidująca. Będzie ona sprawdzać poprawność przesłanych danych względem tego, co mówi specyfikacja. Niezgodności z nią są wypisane na terminalu, towarzyszy temu wytłumaczenie co dokładnie jest niezgodne ze specyfikacją. Warstwa walidująca upewnia się, że program będzie działać tak samo niezależnie od wersji sterownika lub typu procesora graficznego. Niezgodność nie oznacza, że dany kod będzie skutkował błędnym wynikiem, natomiast nie ma gwarancji, że wynik ten nie zmieni się, jeżeli domyślny stan będzie się różnić w innym środowisku pracy. Wsparcie danej warstwy jest opcjonalne, przykładowo warstwy potrzebne tylko podczas tworzenia oprogramowania nie muszą być załączane razem z plikami programu, co zmniejsza jego rozmiar. Aby sprawdzić czy dana warstwa jest w danym środowisku wspierana, należy wykorzystać funkcję _vkEnumerateInstanceLayerProperties_. Kod [isValidationLayerSupported] przedstawia wykorzystanie tej funkcji do sprawdzenia czy przesłana nazwa warstwy walidującej znajduje się w wspieranych warstwach. Warto zauważyć podejście do rozwiązania problemu dynamicznej ilości danych na granicy interfejsu jakie wybrał Vulkan, funkcja przyjmuje dwa argumenty, z czego jeden to wskaźnik na liczbę całkowitą, a drugi to wskaźnik na tablicę elementów wyjściowych. Funkcja posiada dwustanowe zachowanie, jeżeli wskaźnik na tablicę elementów wyjściowych równy jest _NULL_ to liczba wszystkich dostępnych warstw jest wpisana przez wskaźnik zmiennej określającej ilość elementów, funkcja nie wykonuje w tym stanie żadnych innych operacji. Po wyjściu z tej funkcji użytkownik wie, ile elementów musi dynamicznie zaalokować, żeby pomieścić wszystkie dostępne warstwy. W drugim stanie, jeżeli wskaźnik na tablicę elementów wyjściowych jest niezerowy, to odczytywana jest przez wskaźnik liczba ilości elementów dostępnych w tablicy wyjściowej oraz pod koniec zostaje nadpisana faktyczną ilością elementów wpisanych. W tablicy wyjściowej użytkownik ma dostęp do właściwości warstw, takich jak ich nazwa, wersja specyfikacji, wersja implementacji oraz krótki opis, jeżeli znajduje się w niej warstwa o takiej samej nazwie jaka została przesłana do funkcji, zostaje zwrócona wartość boolowska wskazująca na prawdę lub fałsz w przypadku braku szukanej warstwy.

Tworzenie instancji odbywa się przy użyciu funkcji _vkCreateInstance_, cechy charakterystyczne jej interfejsu są powielone we wszystkich pozostałych procedurach zdefiniowanych w _Vulkan_. Funkcja zawsze zwraca obiekt typu _VkResult_, który jest enumeracją wszystkich możliwych rezultatów wykonania. Jest to podstawowa forma raportowania błędów, pomyślnie wykonana funkcja zawsze zwróci wartość _VK_SUCCESS_. Dla porównania, OpenGL zwraca kod błędu poprzez wykorzystanie osobnej funkcji _glGetError_, a takie podejście wymaga globalnego stanu, który gorzej współpracuje z wieloma wątkami chcącymi raportować błędy. Architektura _Vulkan_ brała pod uwagę raportowanie błędów od samego początku tworzenia, kod błędu zwrócony jako wynik funkcji nie wymaga globalnego stanu, przez co wielowątkowe wykorzystanie _Vulkan_ jest możliwe. Znany jest problem, w którym niemożliwe jest rozłożenie pracy podczas korzystania z OpenGL na wiele wątków, a przez to jeden wątek staje się mocniej obciążony niż reszta podczas wysyłania danych na kolejkę procesora graficznego. Stanowi to problem w aplikacjach wykorzystujących zaawansowaną grafikę trójwymiarową, głównie w grach, ponieważ w obecnych czasach prędkość pojedynczego rdzenia jednostki centralnej rośnie o wiele wolnej niż ich ilość. Niewykorzystanie możliwości wielowątkowych dzisiejszych jednostek centralnych nakłada ograniczenia na rzeczy, które są możliwe do wykonania, odejście od globalnego stanu to jeden z kroków podjętych celem wspierania pracy wielowątkowej przez _Vulkan_.

Funkcja tworząca instancję przyjmuje trzy argumenty, które również ukazują jakie rozwiązania zostały przyjęte podczas tworzenia samego interfejsu, argumenty to następująco: wskaźnik na obiekt opisujący jak stworzyć instancję, wskaźnik na obiekt opisujący jak zarządzać pamięcią po stronie jednostki centralnej oraz obiekt wyjściowy samej instancji. Konfigurację tworzonego obiektu przechowuje się w dostarczonych do tego strukturach, pozwala to na zmniejszenie ilości parametrów przesyłanych do każdej z funkcji upraszczając jej wykorzystanie. Vulkan udostępnia możliwość sterowania alokacją pamięci po stronie jednostki centralnej programiście, wykorzystuje do tego obiekt struktury _VkAllocationCallbacks_, w którym znajdują się wskaźniki na funkcje alokujące i zwalniające pamięć. Częstym jest tworzenie niestandardowych obiektów zarządzających alokacją pamięci, celem zwiększenia wydajności programu oraz zmniejszenie szansy na wyciek pamięci. Jeżeli zamiast wskaźnika na obiekt alokatora zostanie przesłana wartość _NULL_, _Vulkan_ wykorzysta domyślny interfejs _malloc_ i _free_ do zarządzania pamięcią. Ostatnim argumentem w funkcjach tworzących jest zawsze wskaźnik na obiekt tworzony, do którego będzie wpisany wynikowy obiekt, ponieważ wartość zwracana przez funkcję jest już zawsze wykorzystana do zwracania kodu błędu. Funkcja ukazana w kodzie [createInstance] tworzy instancję _Vulkan_ z załączoną warstwą walidującą jeżeli taka jest dostępna. Konfiguracja instancji umożliwia podania informacji na temat aplikacji, takich jak jej nazwa, wersja, nazwa silnika oraz jego wersja i finalnie wersja API Vulkan. Dane te umożliwiają twórcom sterowników graficznych na optymalizację zachowania najpopularniejszych programów, na przykład silników do tworzenia gier, takich jak Unity czy Unreal Engine. Każda struktura w Vulkan posiada pole _sType_ i odpowiadającą tej strukturze wartość enumeracyjną, pozwala to na dowolne rozszerzanie pewnych struktur poprzez tworzenie listy połączonej, w których to jaka struktura znajduje się w danym elemencie listy określone jest przez pole _sType_. Po stworzeniu obiektu struktury _VkApplicationInfo_, jego adres pamięci zostaje zapisany w finalnym obiekcie konfigurującym tworzenie instancji, ten jest rozszerzony o warstwą walidującą, jeżeli taka jest wspierana. Wywołanie ostatecznej funkcji owinięte jest w makro sprawdzające, czy zwrócony kod błędu równy jest _VK_SUCCESS_.

Wybór fizycznego urządzenia odbywa się poprzez wysłanie zapytania do interfejsu o enumerację wszystkich obecnych urządzeń w tym systemie. Użytkownik następnie dokonuje wyboru, który procesor graficzny spełnia jego wymagania. Może dokonywać zapytań o to, jakie funkcjonalności wspiera dane urządzenie oraz jakie są jego specyfikacje. Nie można oczekiwać, że w systemie zawsze będzie znajdować się tylko jeden procesor graficzny. Przykładami systemów posiadających więcej niż jeden procesor graficzny mogą być laptopy z procesorem graficznym dedykowanym oraz zintegrowanym z jednostką centralną lub serwery, na których często znajduje się wiele takich samych procesorów graficznych współpracujących ze sobą. W kodzie [findPhysicalDevice] dokonywana jest dokładnie ta operacja, z założeniem, iż wybrane zostanie zawsze pierwsze zwrócone urządzenie fizyczne.

Na podstawie urządzenia fizycznego tworzone jest urządzenie logiczne, wymaga ono opisania z jakich kolejek będzie korzystać program. Przykładowo, program graficzny będzie korzystać z kolejki wspierającej operacje graficzne, natomiast program uruchamiający tylko i wyłącznie shadery obliczeniowe będzie korzystać z kolejki wspierającej arbitralne obliczenia. W funkcji [createDevice] dane te są wpisywane do obiektu typu _VkDeviceQueueCreateInfo_, dla tego programu stworzona zostanie jedna kolejka, z priorytetem równym jeden, ten może przyjąć dowolną wartość zmiennoprzecinkową pomiędzy zero a jeden dla każdej tworzonej kolejki. Stworzone kolejki będą typu, który wskazuje indeks rodziny kolejki, ten został pobrany poprzez enumerację wszystkich kolejek na danym urządzeniu fizycznym przy użyciu _vkGetPhysicalDeviceQueueFamilyProperties_ i wybraniu tej, która ma ustawioną flagę _VK_QUEUE_COMPUTE_BIT_.

Następnie użytkownik ma możliwość włączenia danych specjalnych funkcji procesora graficznego, przykładowo obsługa typu zmiennoprzecinkowego podwójnej precyzji, która domyślnie jest wyłączona. Dodatkowo, istnieje możliwość zdefiniowania rozszerzeń, które mają zostać włączone, rozszerzeniami są nowe niezdefiniowane przez specyfikacje komendy, struktury i wartości enumeracyjne. Przykładem jest rozszerzenie _VK_NV_COOPERATIVE_MATRIX_, pozwalające użytkownikowi na wykorzystanie rdzeni tensorowych, znajdujących się tylko na urządzeniach najnowszych generacji od NVIDIA. Wspieranie takiej funkcjonalności nie może być dodane przez specyfikację, ponieważ nie wszystkie procesory graficzne będą wspierać to rozszerzenie. Mimo wszystko posiadanie rozszerzeń do urządzenia pozwala interfejsowi _Vulkan_ być bardziej elastycznym w wspieraniu wielu pofragmentowanych rozwiązań. Ponieważ program wymaga wykorzystania operacji atomicznych dla wybranych algorytmów należy je włączyć poprzez dodanie rozszerzenia _VK_EXT_shader_atomic_float_. Nazwa rozszerzenia zostaje dodana do tablicy włączonych rozszerzeń, a konfiguracja tego rozszerzenia zdefiniowana przez strukturę _VkPhysicalDeviceShaderAtomicFloatFeaturesEXT_, w której włączona jest atomiczna operacja dodawania zostaje dodana do pola _pNext_, które służy do rozszerzenia tej struktury przy użyciu listy połączonej. Po skonfigurowaniu tych opcji może zostać stworzone urządzenie logiczne, przy jego pomocy będzie wykonywana cała komunikacja z procesorem graficznym. Jako ostatni pobierany jest logiczny odnośnik do kolejki, na którą będzie wysyłana praca do wykonania przez procesor graficzny.

Ostatni krok w ogólnej inicjalizacji to stworzenie dwóch pul pamięci dla komend i kwerend. Podejście takie pozwala na posiadanie tylko jednego określonego miejsca, w którym znajduje się pamięć danej rzeczy, tym samym zwiększając lokalność pamięci. Funkcje odpowiedzialne za stworzenie obu tych obiektów przedstawione są w kodzie [commandAndPoolCreation]. Stworzenie puli dla komend wymaga podania indeksu kolejki na urządzeniu fizycznym, do której będą wysyłane komendy zaalokowane w tej puli. Pula dla kwerend natomiast wymaga logicznego urządzenia, na którym będą wykonywane kwerendy, ich typ oraz maksymalna ilość.

Na podstawie tego globalnego stanu zostają utworzone dodatkowe obiekty, będące odpowiedzialne za uruchomienie poszczególnych shaderów obliczeniowych dla danego formatu przechowywania macierzy. Dla każdego formatu są to te same obiekty tworzone w tej samej kolejności, natomiast różnią się na przykład rozmiarem lub ilością. Zbiór wszystkich obiektów potrzebnych do komunikacji z procesorem graficznym celem wywołania poszczególnego shadera dla wybranego typu macierzy nie będących stanem globalnym od tego miejsca nazwano scenariuszem. Każdy scenariusz zawierał następuje obiekty: pary buforów i pamięci, pulę deskryptorów, ich ułożenie oraz zbiór, definicję potoku oraz bufor komend. Przykładowa struktura opisująca scenariusz znajduje się w kodzie [BSRScenario].

W uproszczeniu, bufor jest wglądem do pamięci w zdefiniowanym zakresie, natomiast pamięć jest obiektem przy pomocy którego zarządzamy czasem życia danej alokacji pamięci. Takie rozwiązanie pozwala na stworzenie wielu różnych zmieniających się wglądów do zaalokowanej pamięci bez potrzeby jej ciągłej realokacji. Grupy bufora i pamięci zawsze były tworzone w parze, jedna reprezentowała pamięć, do której jednostka centralna ma dostęp natomiast druga reprezentowała pamięć lokalną dla procesora graficznego. Jest to wymagane, ponieważ jednostka centralna nie może bezpośrednio dokonywać arbitralnych operacji na lokalnej pamięci procesora graficznego. Bufor wykorzystywany do przepisywania pamięci z jednostki centralnej do pamięci procesora graficznego nazywa się buforem przestojowym (ang. staging buffer). Zanim bufor zostanie stworzony należy określić jego rozmiar, sposób współdzielenia pomiędzy kolejkami i to, w jaki sposób będzie wykorzystywany, np. dla bufora przestojowego wykorzystywana jest możliwość przechowywania danych oraz bycie źródłem podczas transferu. Po stworzeniu bufora należy dokonać kwerendy celem określenia wyrównanego rozmiaru pamięci oraz jakie typy pamięci, które posiada urządzenie będą wspierać wszystkie zdefiniowane sposoby wykorzystywania. Zaalokowanie pamięci wymaga odpytania urządzenia jakie posiada typy pamięci oraz w jakich kopcach się znajdują. Wybór typu pamięci sprowadza się do tego, czy istnieje pamięć, będąca w stanie obsłużyć wszystkie wymagania bufora i czy jest wystarczająco blisko pamięci samego rdzenia mikroprocesora graficznego. Po wskazaniu wyrównanej ilości pamięci do zaalokowania oraz który typ pamięci ma zostać wykorzystany zostaje stworzony obiekt pamięci. Ten finalnie może zostać przypisany do bufora. Funkcja odpowiedzialna za wykonanie tych wszystkich operacji znajduje się w kodzie [createBuffer]. Zakłada ona, że zawsze tylko jedna kolejka będzie miała dostęp do bufora dlatego _sharingMode_ ustawiony jest na wartość wskazującą wyłączony dostęp.

Operacje na pamięci przez jednostkę centralną w buforach wspierających tę operację dokonywane są poprzez zmapowanie tej pamięci do przestrzeni adresowej danego programu. Po tym, procesor ma dostęp do wszystkich bajtów w sposób równoważny pamięci zaalokowanej na przykład przez funkcję _malloc_. Program ma obowiązek usunąć mapowanie pamięci przed wykorzystaniem jej do komunikacji z procesorem graficznym. Przykładowa funkcja w kodzie [inVecToSSBO] przy użyciu funkcji _vkMapMemory_ i _vkUnmapMemory_ przenosi zawartość wektora do pamięci bufora przestojowego.

Zaprzęgnięcie procesora graficznego do faktycznego wykonywania pracy wymaga wysłania bufora z nagranymi komendami na daną kolejkę. Aby nagrać komendy potrzebne jest miejsce, które będzie zapisywać liniowy ciąg wywołanych komend, jest nim bufor komend, a do jego alokacji należy wskazać na pulę komend, która będzie zarządzać stworzonymi buforami komend. Taki bufor komend jest rozpoczynany i od tego momentu wszystkie wywołane procedury będące komendą są liniowo dodawane do tego bufora komend, aż do zakończenia jego nagrywania. Gotowy bufor zostaje wysłany na kolejkę, która ma go wykonać, w przypadku implementowanego programu jest to kolejka obliczeniowa. Celem tworzonego programu jest zachowanie synchroniczności podczas komunikacji z procesorem graficznym, więc zaraz po zakolejkowaniu operacji program czeka, aż kolejka będzie bezczynna, co będzie wskazywać na wykonanie bufora komend. Funkcja przedstawiona w kodzie [copyStagingBufferToDevice] przy wykorzystaniu buforów komend kopiuje dane z bufora przestojowego do bufora znajdującego się w pamięci globalnej procesora graficznego. Tworząc bufor komend możliwe jest określenie dwóch poziomów, bufor główny może wykonać nagrany bufor drugorzędny oraz samemu być przesłanym na kolejkę. Bufor drugorzędny może być jedynie wykonany w kontekście bufora głównego oraz nie może być przesłany na kolejkę. Ponieważ dla tego zastosowania bufor zostaje zwolniony po jego wykonaniu, dodatkowo przesłana jest flaga w obiekcie struktury _VkCommandBufferBeginInfo_ wskazując na fakt, iż bufor ten zostanie uruchomiony tylko raz. Używając komendy _vkCmdCopyBuffer_, do której argumentem jest obiekt określający cały rozmiar bufora bez żadnego przesunięcia ani w buforze źródłowym ani w buforze docelowym, dokonywana jest kopia bufora. Nagrany bufor komend zostaje przesłany na kolejkę funkcją _vkQueueSubmit_ oraz przy użyciu _vkQueueWaitIdle_ program po stronie jednostki centralnej czeka na zakończenie operacji.

Pula deskryptorów pełni taką samą rolę jak pula komend i kwerend, alokacje deskryptorów są lokalizowane do danej puli ułatwiając zarządzanie. W kodzie [createDescriptorPool] przedstawiona jest funkcja, tworząca pulę deskryptorów, z której będzie można zaalokować jeden deskryptor typu _VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_. W konfiguracji tworzenia zostaje przesłana flaga pozwalająca na zwalnianie zaalokowanych deskryptorów z powrotem do puli, bez tej flagi jedyne operacje jakie są dostępne to wykorzystanie puli do alokacji i jej zrestartowanie. Ponieważ konfiguracja przyjmuje tablicę rozmiarów do zaalokowania, jedna pula może służyć jako globalna pula, z której alokowane są deskryptory różnych typów.

Deskryptor reprezentuje zasób dostępny shaderowi, na przykład bufor lub sampler tekstur. Zdefiniowanie deskryptora wymaga stworzenia obiektu zestawu deskryptorów, a to z kolei wymaga opisania układu deskryptorów w zestawie poprzez stworzenie obiektu układu zestawu deskryptorów. Funkcja [createConsecutiveDescriptorSetLayout] tworzy układ, w którym każdy deskryptor będzie następować po sobie, określamy indeks w zestawie, pod którym ten deskryptor będzie dostępny, jego typ oraz ilość, a gdy ta jest większa niż jeden umożliwia to stworzenie tablicy obiektów, na przykład takich jak samplery tekstur w shaderze. Różnica pomiędzy ilością deskryptorów w danym powiązaniu została przedstawiona na rysunku [descriptorCount].

Na podstawie jednego lub większej ilości układów zestawu deskryptorów funkcja [createDescriptorSet] tworzy obiekt zestawu deskryptorów, który obecnie jest tylko sposobem interpretacji podłączonych zasobów, natomiast nie posiada żadnych zasobów powiązanych ze sobą.

Przypisanie buforów odbywa się poprzez aktualizację zestawu deskryptorów, wymagane informacje to: który zestaw deskryptorów jest modyfikowany, który indeks w tym zestawie oraz ilość deskryptorów w tym indeksie, jakie należy zaktualizować. Sam zasób jest określany przez jeden z trzech różnych wskaźników na obrazy, bufory lub określony zakres bufora, dla buforów określany jest identyfikator bufora, przesunięcie względem początku oraz rozmiar, jaki ma być zmapowany. Ilość deskryptorów określa ilość elementów znajdujących się pod jednym z tych trzech wskaźników, to który z nich będzie wybrany określa typ deskryptora. Funkcja przypisująca bufory do deskryptorów przy pomocy funkcji _vkUpdateDescriptorSets_ przedstawiona jest w kodzie [bindDescriptorSetWithBuffers], jako parametry wejściowe przyjmuje buforów i przesunięcia w pamięci do nich i przypisuje je do układu deskryptorów stworzonego przez funkcję w kodzie [createConsecutiveDescriptorSetLayout].

Tak stworzony i zaktualizowany z przypisanymi buforami zestaw deskryptorów może następnie być wykorzystany podczas tworzenia potoku obliczeniowego. Będzie on uruchamiał dany shader, więc stworzony zostaje moduł shadera poprzez wykorzystanie danych binarnych w formacie SPIR-V. Następnie stworzony zostaje układu potoku, który wymaga podania układu deskryptorów oraz opcjonalnie zestawu stałych, które mają zostać przesłane do shadera. Ostatnimi informacjami do określenia to struktura opisująca etap potoku, posiada ona informacje o shaderze, takie jak jego moduł, nazwa funkcji wejściowej i typ etapu, w tym przypadku jest to etap obliczeniowy. Przy pomocy tych informacji zostaje stworzony potok obliczeniowy, który hermetyzuje sposób uruchomienia danego shadera i informacji z nim związanych. Funkcja przedstawiona w kodzie [createComputePipeline] jest odpowiedzialna za wszystkie wyżej wymienione kroki, jej rezultatem jest układ potoku zwierający dane o sposobie ułożenia deskryptorów i zestawie stałych oraz sam obiekt opisujący potok, który opisuje etap potoku oraz shader, który zostanie uruchomiony.

Aby go uruchomić należy stworzyć nowy bufor komend, rozpocząć jego nagrywanie i wywołać następujące komendy: przypisanie potoku, przypisanie zestawu deskryptorów, zrestartowanie puli kwerend, wpisanie obecnego znacznika czasowego do puli kwerend, wywołanie X × Y × Z grup inwokujących shader z tego potoku oraz wpisanego drugiego znacznika czasowego po zakończonych inwokacjach shadera, po czym nagrywanie bufora zostaje zakończone. Funkcja [createCommandBuffer] tworzy i nagrywa taki bufor komend na podstawie przesłanego obiektu potoku, zestawu deskryptorów oraz ilości grup, które mają być wywołane podczas uruchomienia. Tak nagrany bufor komend zostaje przesłany na kolejkę obliczeniową urządzenia, celem jego wykonania. Gdy kolejka przejdzie w stan bezczynności wszystkie komendy zostały wykonane, tak samo jak w przypadku funkcji [copyStagingBufferToDevice]. Przy użyciu obiektu puli kwerend pobierane zostają dwa znaczniki czasowe, a różnica pomiędzy nimi opisuje czas potrzebny na wykonanie tego shadera dla użytych danych.


Implementacja mnożenia macierz - wektor dla każdego z formatów 

Rozdział ten przedstawia sposób przechowywania w kodzie każdej z macierzy i shader wykorzystujący dany format do obliczenia iloczynu macierz-wektor.

Format COO

Kod [coo_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie COO.

Shader ukazany w kodzie [coo_shader] oblicza wynik mnożenia macierzy w formacie COO z wektorem. Przyjmuje cztery bufory wejściowe i jeden wyjściowy. Pierwsze trzy opisują kolejno: nagłówek macierzy, tablicę wartości, kolumn i rzędów elementów. Czwarta jest tablicą traktowaną jako wejściowy wektor, natomiast piąta jest wektorem wyjściowym. Każda inwokacja shadera określa swój globalny identyfikator jako dostarczona przez shader zmienna _gl_GlobalInvocationID.x_. Zmienna ta jest określona na podstawie identyfikatora grupy, lokalnego identyfikatora wątku wewnątrz grupy oraz rozmiaru lokalnej grupy. Ta ustawiona jest na wartość równą 32, aby być kompatybilna z rozmiarem _warp_’u, czyli najmniejszej jednostki przydzielenia pracy do _SM_. Globalny identyfikator służy jako indeks do określenia, jaką pracę ma wykonać każdy z wątków. Jeżeli indeks jest większy niż liczba wszystkich elementów wątek ten nie wykonuje żadnej pracy. W przeciwnym przypadku, wątek pobiera rząd oraz kolumnę elementu znajdującego się pod tym indeksem. Określa iloczyn wartości elementu z wartością w wejściowym wektorze, znajdującym się pod indeksem kolumny elementu. Następnie atomicznie dodaje go do wartości wektora wyjściowego, znajdującej się pod indeksem rzędu elementu. Atomiczna operacja wymagana jest ze względu na fakt, iż wątek ten nie ma wyłącznego dostępu do zapisu w tej komórce. Inne wątki w tym samym czasie mogą chcieć zapisać do tego samego miejsca, co skutkuje wyścigiem danych.

Format CSR

Kod [csr_struct] przedstawia strukturę będąca odpowiedzialna za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie CSR.

Shader ukazany w kodzie [csr_shader] oblicza wynik mnożenia macierzy w formacie CSR z wektorem. Bufory wejściowe są takie same jak w przypadku macierzy COO. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia. Jeżeli indeks jest większy niż liczba wszystkich rzędów wątek ten nie wykonuje żadnej pracy. W przeciwnym wypadku pobiera przesunięcie do tablic _floatdata_ i _columnIndex_, pod którym zaczynają się elementy dla tego rzędu. Na podstawie tablicy _rowOffsets_ ustala również ilość elementów niezerowych w tym rzędzie jako różnica przesunięcia następnego rzędu a rzędu obecnego. Fakt, iż długość tablicy _rowOffsets_ jest o jeden większa niż liczba rzędów, a ostatni element równy jest liczbie wszystkich elementów niezerowych pozwala na uniknięcie potrzeby wykorzystania specjalnego wyjątku, w którym dla ostatniego rzędu wykorzystywana jest wartość _elementNum_. Takie uproszczenie kodu pozwala mu na wyższą wydajność. Shader następnie, iterując po wszystkich niezerowych elementach, do lokalnej zmiennej _prod_ sumuje wszystkie iloczyny wartości elementów występujących w tym rzędzie. Ponieważ każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek. Usuwa to potrzebę bazowania na operacjach atomicznych, co przyśpiesza wykonanie shadera.

Format CSC

Kod [csc_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie CSC.

Shader ukazany w kodzie [csc_shader] oblicza wynik mnożenia macierzy w formacie CSC z wektorem. Bufory wejściowe są takie same jak w przypadku macierzy COO. Globalny identyfikator traktowany jest jako indeks kolumny, na którym mają zostać wykonane obliczenia. Jeżeli indeks jest większy niż liczba wszystkich rzędów kolumn, ten nie wykonuje żadnej pracy. W przeciwnym wypadku pobiera przesunięcie do tablic _floatdata_ i _rowIndex_, pod którym zaczynają się elementy dla tej kolumny. Na podstawie tablicy _columnOffsets_ ustala również ilość elementów niezerowych w tej kolumnie jako różnica przesunięcia następnej kolumny, a kolumny obecnej. Shader następnie, iterując po wszystkich niezerowych elementach, oblicza produkt pomiędzy wektorem , a danym elementem macierzy w tej kolumnie. Ze względu na przechodzenie po kolumnach zamiast po rzędach dana inwokacja shadera nie gwarantuje wyłączności do danej komórki wektora wyjściowego. Uniknięcie wyścigu danych wymaga wykorzystania atomicznej operacji dodawania.

Format ELL

Kod [ell_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie ELL.

Shader ukazany w kodzie [ell_shader] oblicza wynik mnożenia macierzy w formacie ELL z wektorem. Bufory wejściowe są podobne jak w przypadku macierzy COO, natomiast shader nie wymaga tablicy określającej rząd danego elementu i dodatkowo w nagłówku przesłana zostaje wartość P. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia. Jeżeli indeks jest większy niż liczba wszystkich rzędów wątek ten nie wykonuje żadnej pracy. W przeciwnym wypadku oblicza przesunięcie do tablic _floatdata_ i _columnIndices_, pod którym zaczynają się elementy dla tego rzędu. Następnie iterując w pętli do teoretycznego maksymalnego indeksu P, określany jest indeks elementu w obu tablicach. Jeżeli dla tego elementu wartość w _columnIndices_ wskazuje na brak danych, praca tego wątku zostaje przerwana. W przeciwnym przypadku, obliczony zostaje produkt, który jest sumowany do zmiennej lokalnej _prod_, która pod koniec zostaje wpisana do wektora wyjściowego. Każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek bez potrzeby wykorzystania operacji atomicznych.

Format SELL

Kod [sell_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie SELL.

Shader ukazany w kodzie [sell_shader] oblicza wynik mnożenia macierzy w formacie SELL z wektorem. Bufory wejściowe są identyczne jak w przypadku macierzy CSR, dodatkowo w zmiennej C nagłówek zawiera wysokość paska dla tej macierzy. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia. Jeżeli indeks ten jest większy niż liczba wszystkich rzędów wątek, ten nie wykonuje żadnej pracy. W przeciwnym wypadku obliczony zostaje indeks paska oraz indeks rzędu wewnątrz paska na podstawie globalnego indeksu rzędu i wartości C, wartość ta służy też do określenia ilości kolumn w tym pasku przy wykorzystaniu tablicy _rowOffsets_, jako różnica przesunięcia następnego paska, a paska obecnego podzielona przez wartość C. Pobrane zostaje również przesunięcie do tablic _floatdata_ i _columnIndex_, pod którym zaczynają się elementy dla tego paska. Wartości pasków przechowywane są kolumnowo, aby umożliwić procesorowi graficznemu łączenie dostępów do pamięci pomiędzy wątkami, ze względu na to, pierwszy element należący do danego wątku to przesunięcie w pamięci do obecnego paska plus indeks rzędu wewnątrz paska. Iterując przez wszystkie kolumny w pasku, do zmiennej lokalnej _prod_ sumowane zostaje iloczyn elementu macierzy z elementem wektora wejściowego. Aby uniknąć operacji warunkowej sprawdzającej obecność danych w elemencie, pod uwagę brane są wszystkie komórki macierzy wejściowej. W miejscach gdzie nie ma danych znajduje się zero, które podczas mnożenia nie produkuje wartości wypływających na wynik ostateczny. Każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek bez potrzeby wykorzystania operacji atomicznych.

Format BSR

Kod [bsr_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie BSR.

Shader ukazany w kodzie [bsr_shader] oblicza wynik mnożenia macierzy w formacie BSR z wektorem. Bufory wejściowe są identyczne jak w przypadku macierzy CSR. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia, na jego podstawie obliczany jest indeks rzędu blokowego i indeks rzędu wewnątrz bloku. Jeżeli indeks rzędu blokowego jest większy niż liczba wszystkich rzędów blokowych lub indeks rzędu wewnątrz bloku jest większy niż rozmiar bloku, to wątek ten nie wykonuje żadnej pracy. W przeciwnym wypadku pobiera przesunięcie do tablic _floatdata_ i _columnIndex_, pod którym zaczynają się elementy dla tego rzędu blokowego. Na podstawie tablicy _rowOffsets_ ustalona zostaje ilość bloków niezerowych w tym rzędzie blokowym jako różnica przesunięcia następnego rzędu blokowego a rzędu obecnego. Iterując przez wszystkie kolumny blokowe, obliczane jest przesunięcie dla tego bloku i pobierana zostaje blokowa wartość kolumny tego bloku. W mniejszej pętli przechodzącej przez każdą kolumnę w bloku, która znajduje się na przypisanym temu wątkowi rzędzie, do zmiennej lokalnej _prod_ sumowany zostaje iloczyn elementów macierzy z elementem wektora wejściowego. Każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek bez potrzeby wykorzystania operacji atomicznych.
