

WPROWADZENIE


Procesory graficzne z wielu punktów widzenia są kompletnie różne od zwykłej jednostki centralnej w każdym komputerze. Mają nienaturalną konstrukcję, skupiającą się na posiadaniu jak największej ilości jednostek arytmetycznych w krzemie. Wynikiem tego jest nieosiągalnie duża dla zwykłych mikroprocesorów, surowa moc obliczeniowa. Niecodzienność struktury tej rodziny procesorów czyni tworzenie programów rozwiązujących dany problem bardziej skompilowane. Ilość dostępnych języków programowania dla procesorów graficznych jest znikoma w porównaniu do języków pozwalających na programowanie przykładowo jednostki centralnej z architekturą x86. Procesory graficzne mogą wspierać różne ISA w tej samej chwili, umożliwia to ciągle działający sterownik, który tłumaczy daną abstrakcję na odpowiedni dla tej mikro-architektury kod maszynowy. Tak jak w nowoczesnych jednostkach centralnych, finalnie wykonywany kod maszynowy nazywany mikrokodem, często zmienia się pomiędzy architekturami; dla przykładu firma AMD udostępnia specyfikację mikrokodu publicznie, natomiast firma NVIDIA nie udostępnia takich danych. Przykładową abstrakcją wyższą jest język pośredni SPIR-V stworzony na potrzeby obliczeń wielowątkowych i graficznych. Załadowanie i uruchomienie tego kodu umożliwia specyfikacja Vulkan, opisująca zestaw interfejsów pozwalających na kontrolowanie zachowania procesora graficznego.


Cele pracy

Celem poniższej pracy jest implementacja algorytmów mnożenia macierzy rzadkich przez wektor oraz przedstawienie użytego interfejsu do procesora graficznego. Praca również omawia ogólną mikro-architekturę procesorów graficznych i uruchamianie shaderów obliczeniowych na nich.


Zawartość pracy

W rozdziale 2 omówiono problem macierzy rzadkich i formatów do ich przetrzymywania. Następnie w rozdziale 3 przedstawiono ogólną mikro-architekturę nowoczesnych procesorów graficznych. Opisano użyty interfejs Vulkan do zarządzania procesorem graficznym, czym są shadery obliczeniowe. Sposób implementacji komunikacji z procesorem graficznych oraz poszczególnych shaderów obliczeniowych zawarto w rozdziale 4. Uzyskane wyniki używając tej implementacji przeanalizowano w rozdziale 5, a podsumowanie pracy przedstawiono w rozdziale 6.



MNOŻENIE MACIERZ-WEKTOR DLA MACIERZY RZADKICH


Problem mnożenia macierzy przez wektor

Operacja taka jest specjalnym przypadkiem mnożenia macierzy przez macierz, gdy liczba kolumn w drugiej macierzy równa jest jeden. Macierz o liczbie rzędów M i liczbie kolumn N zostaje pomnożona przez wektor o liczbie rzędów równej ilości kolumn macierzy. Dla macierzy A o wymiarach M × N i wektora X o wymiarach N × 1 możemy następująco przedstawić operację mnożenia Y = AX. Wynikowy wektor Y będzie posiadał liczbę rzędów równą liczbie rzędów macierzy wejściowej, wymiary wektora to finalnie M × 1.


Macierze rzadkie

Macierz rzadka jest specjalnym przypadkiem macierzy, w której większość jej elementów jest równa zero. Możemy zaobserwować, że dla elementów zerowych mnożenie zawsze będzie skutkować wynikiem równym zero. Poświęcanie czasu obliczeniowego do ewaluacji iloczynu tych elementów jest zbędne. Ilość pamięci jaka wymagana jest do przetrzymania macierzy rośnie kwadratowo wraz ze wzrostem jej wymiaru. Jeżeli przyjmiemy, że tylko n_(z) elementów w macierzy jest niezerowych, teoretycznie możliwe jest następujące zmniejszenie zużycia pamięci i przyśpieszenie obliczeń:

$$R = \frac{M N}{n_z}$$

krotność zmniejszenia zużycia pamięci oraz krotność przyśpieszenia obliczeń

ilość elementów niezerowych w macierzy

liczba rzędów macierzy

liczba kolumn macierzy


Problem mnożenia macierzy rzadkiej przez wektor

Istnieje pole problemów, których rozwiązanie zawsze wymaga pracy z macierzami rzadkimi. Przykładem jest metoda elementów skończonych (MES), w której ostateczne określenie wartości w węzłach jest rozwiązaniem układu równań, w którym macierz jest rzadka. Obliczenia na większych macierzach zazwyczaj dokonywane są przez metody iteracyjne. Podstawową operacją w tych metodach jest mnożenie macierzy rzadkiej przez wektor wiele razy, aby otrzymać jak najlepsze przybliżenie.


Formaty macierzy rzadkich

Główny problem w przechowywaniu macierzy rzadkich to sposób w jaki określony zostaje rząd oraz kolumna dla danego elementu. Samo przechowywanie tylko elementów niezerowych jest elementem wspólnym prawie wszystkich formatów. Występują jednak formaty, które przetrzymują część elementów zerowych, aby uprościć oszacowanie rzędu i kolumny. Zmniejsza to narzut pamięciowy przetrzymywania danych dodatkowych przy tablicy elementów niezerowych.

Formaty omówione to:

-   COO (ang. Coordinate Format) - najprostszy format, który wykorzystuje trzy tablice _row_, _col_, _floatdata_. Odpowiednio przechowują one rząd, kolumnę i wartość elementu _i_’tego. Długość tablic równa jest ilości elementów niezerowych.

    Reprezentacja wizualna transformacji przykładowej macierzy:
    $$\left[
    \begin{array}{ccccc}
        1 & 4 & 0 & 0 & 0\\ 
        0 & 2 & 3 & 0 & 0\\ 
        5 & 0 & 0 & 7 & 8\\ 
        0 & 6 & 0 & 8 & 0\\ 
    \end{array}
    \right]
    \rightarrow
    \begin{matrix}
    \text{floatdata} & = & \begin{bmatrix}
    1 & 4 & 2 & 3 & 5 & 7 & 8 & 6 & 8 \\
    \end{bmatrix} \\
    \text{row} & = & \begin{bmatrix}
    0 & 0 & 1 & 1 & 2 & 2 & 2 & 3 & 3 \\
    \end{bmatrix} \\
    \text{col} & = & \begin{bmatrix}
    0 & 1 & 1 & 2 & 0 & 3 & 4 & 1 & 3 \\
    \end{bmatrix} \\
    \end{matrix}$$

-   CSR (ang. Compressed Sparse Row Format) - format rzędowo kompresuje macierz przez zapisywanie wszystkich wartości z danego rzędu bezpośrednio po sobie. Takie podejście umożliwia nieprzechowywanie rzędu elementu wprost, a jedynie indeks początkowego elementu wiersza. Dwie tablice _floatdata_ i _columnIndices_ są nadal długości równej ilości elementów niezerowych i przechowują one odpowiednio wartość i kolumnę elementu _i_’tego. Trzecia tablica _rowOffsets_ ma długość o jeden większą niż ilość rzędów macierzy, co dla macierzy o większych zagęszczeniach pozwala zaoszczędzić na pamięci w porównaniu do formatu COO. Dla numeru rzędu r będący wartością z przedziału [0, N − 1] format przechowuje indeks pierwszego elementu w tablicach _floatdata_ i _columnIndices_, należącego do tego rzędu. Liczbę elementów niezerowych w danym wierszu można obliczyć jako różnicę pomiędzy indeksem w wierszu r + 1, a indeksem w wierszu r.

    Reprezentacja wizualna transformacji przykładowej macierzy:
    $$\left[
    \begin{array}{ccccc}
        1 & 4 & 0 & 0 & 0\\ 
        0 & 2 & 3 & 0 & 0\\ 
        5 & 0 & 0 & 7 & 8\\ 
        0 & 6 & 0 & 8 & 0\\ 
    \end{array}
    \right]
    \rightarrow
    \begin{matrix}
    \text{floatdata} & = & \begin{bmatrix}
    1 & 4 & 2 & 3 & 5 & 7 & 8 & 6 & 8 \\
    \end{bmatrix} \\
    \text{columnIndices} & = & \begin{bmatrix}
    0 & 1 & 1 & 2 & 0 & 3 & 4 & 1 & 3 \\
    \end{bmatrix} \\
    \text{rowOffsets} & = & \begin{bmatrix}
    0 & 2 & 4 & 7 & 9 \\
    \end{bmatrix} \\
    \end{matrix}$$

-   CSC (ang. Compressed Sparse Column Format) - format kolumnowo kompresuje macierz w identyczny sposób jak format CSR ze zmianą kierunku kompresji. Niezmiennie macierz w tablicy _floatdata_ przechowuje wartość elementu _i_’tego. Format ten zapisuje w pełni rząd elementu _i’tego_ w tablicy _rowIndex_ o długości równej ilości elementów niezerowych. Nieprzechowywane natomiast są kolumny zastąpione przez indeks początkowego elementu kolumny. Zadanie to pełni tablica _columnOffsets_ o długości o jeden większa niż ilość kolumn w macierzy. Jeżeli liczba rzędów jest równa liczbie kolumn macierzy, format ten będzie wymagał tej samej ilości pamięci, co format CSR. Dla problemu mnożenia macierz-wektor najczęściej preferowanym formatem jest CSR ze względu na swoją prostotę i wyższą wydajność osiąganą dzięki braku wymagania wykorzystania operacji atomicznych.

    Reprezentacja wizualna transformacji przykładowej macierzy:
    $$\left[
    \begin{array}{ccccc}
        1 & 4 & 0 & 0 & 0\\ 
        0 & 2 & 3 & 0 & 0\\ 
        5 & 0 & 0 & 7 & 8\\ 
        0 & 6 & 0 & 8 & 0\\ 
    \end{array}
    \right]
    \rightarrow
    \begin{matrix}
    \text{floatdata} & = & \begin{bmatrix}
    1 & 5 & 4 & 2 & 6 & 3 & 7 & 8 & 8 \\
    \end{bmatrix} \\
    \text{rowIndices} & = & \begin{bmatrix}
    0 & 2 & 0 & 1 & 3 & 1 & 2 & 3 & 2 \\
    \end{bmatrix} \\
    \text{columnOffsets} & = & \begin{bmatrix}
    0 & 2 & 5 & 6 & 8 & 9 \\
    \end{bmatrix} \\
    \end{matrix}$$

-   ELL (ang. ELLPACK Format) - format przechowuje podmacierz o wymiarach M × P gdzie P jest maksymalną ilością elementów niezerowych ze wszystkich wierszy. Jest to pierwszy format, który wybiera przechowywać większą ilość danych niż ilość elementów niezerowych. Jego wydajność wzrasta dla macierzy, w których średnia ilość elementów niezerowych w wierszu jest najbardziej zbliżona do P. Wykorzystuje dwie tablice, _floatdata_ i _columnIndices_ obie o wymiarach M × K. Przechowują one kolejno wartości elementów i indeks kolumny, w której znajduje się ten element. Lokalizacja wartości należących do danego rzędu jest prosta, ze względu na stałą P. Zaczynając od indeksu rP następne P elementów należy do wiersza o indeksie r. Jeżeli wiersz posiada mniej elementów niezerowych niż P, pola niewypełnione wartością lub kolumną są ustawione na specjalną wartość traktowaną jako flaga.

    Reprezentacja wizualna transformacji przykładowej macierzy:
    $$\left[
    \begin{array}{ccccc}
        1 & 4 & 0 & 0 & 0\\ 
        0 & 2 & 3 & 0 & 0\\ 
        5 & 0 & 0 & 7 & 8\\ 
        0 & 6 & 0 & 8 & 0\\ 
    \end{array}
    \right]
    \rightarrow
    \begin{matrix}
    \text{floatdata} & = & \begin{bmatrix}
    1 & 4 & X \\
    2 & 3 & X \\
    5 & 7 & 8 \\
    6 & 8 & X \\
    \end{bmatrix} \\
    \end{matrix}
    \quad
    \begin{matrix}
    \text{columnIndices} & = & \begin{bmatrix}
    0 & 1 & X \\
    1 & 2 & X \\
    0 & 3 & 4 \\
    1 & 3 & X \\
    \end{bmatrix} \\
    \end{matrix}$$

-   SELL (ang. Sliced ELLPACK Format) - jest modyfikacją formatu ELL, w której wartość P jest obliczana w obrębie paska wierszy o wysokości C. Umożliwia to ograniczenie efektu, w którym wiersz z dużą ilością elementów sztucznie zwiększa ilość potrzebnej pamięci. Takie sporadyczne wiersze będą jedynie wpływać na rozmiar swojego paska. Najczęściej jednak wartość P pasków będzie zbliżona do wartości średniej ilości elementów niezerowych we wszystkich wierszach. Format wymaga dodatkowej tablicy _rowOffsets_ o długości równej ilości pasków, ta może zostać obliczona jako $\frac{M}{C}$ zaokrąglajac w górę. Tak samo jak w formacie CSR przetrzymuje ona indeks pierwszego elementu w dwóch następnych tablicach odpowiadający _i_’temu paskowi. Tablice te to _floatdata_ i _columnIndices_, pełniące tę samą role, co tablice o tej samej nazwie w formacie ELL. Poprzez sterowanie wartością C zmieniamy zachowanie formatu. W przypadku, gdy C = M mamy tylko jeden pasek, zatem format upraszcza się do ELL. Natomiast dla C = 1, format zachowuje się identycznie jak CSR.

    Reprezentacja wizualna transformacji przykładowej macierzy dla wysokości paska C = 2:
    $$\left[
    \begin{array}{ccccc}
        1 & 4 & 0 & 0 & 0\\ 
        0 & 2 & 3 & 0 & 0\\ 
        5 & 0 & 0 & 7 & 8\\ 
        0 & 6 & 0 & 8 & 0\\ 
    \end{array}
    \right]
    \rightarrow
    \begin{matrix}
    \begin{matrix}
    \text{floatdata} & = & \begin{bmatrix}
    1 & 4 &   \\
    2 & 3 &   \\
    \hline
    5 & 7 & 8 \\
    6 & 8 & X \\
    \end{bmatrix} \\
    \end{matrix}
    \quad
    \begin{matrix}
    \text{columnIndices} & = & \begin{bmatrix}
    0 & 1 &   \\
    1 & 2 &   \\
    \hline
    0 & 3 & 4 \\
    1 & 3 & X \\
    \end{bmatrix} \\
    \end{matrix}

    \\
    \begin{matrix}
    \text{rowOffsets} & = & \begin{bmatrix}
    0 & 4 & 10 \\
    \end{bmatrix} \\
    \end{matrix}
    \end{matrix}$$

-   BSR (ang. Block Compressed Sparse Row Format) - format dzielący i przechowujący macierz jako zbiór bloków o wymiarach B_(s) × B_(s). W specjalnym przypadku, gdy B_(s) = 1 format zachowuje się identycznie jak CSR. Dla wartości większych macierz zostaje skompresowana rzędowo przy założeniu, że najmniejszą komórką jest blok B_(s) × B_(s). W tablicy _floatdata_ przechowywane są dane bloków następująco po sobie, długość tej tablicy równa jest liczbie niezerowych bloków pomnożona przez B_(s)². Kolumnę bloku określa tablica _columnIndices_ o długości równej liczbie niezerowych bloków. Określenie kolumny w przestrzeni macierzy dla elementu w bloku odbywa się przez pomnożenie kolumny bloku przez B_(s) oraz dodanie kolumny elementu wewnątrz bloku. Pierwszy blok należący do rzędu bloku o indeksie r_(b) znajduje się pod indeksem wskazanym przez wartość w tablicy _rowOffsets_, pod indeksem r_(b). Tablica ta ma długość równą $\frac{M}{B_s} + 1$. Obliczenie rzędu w przestrzeni macierzy dla elementu odbywa się podobnie jak dla kolumny, do iloczynu r_(b) i B_(s) zostaje dodany rząd elementu wewnątrz bloku. Dla macierzy o wymiarach nie będących wielokrotnością B_(s) wartości elementów wykraczające poza wymiar macierzy A zostają ustawione na wartość zerową.

    Reprezentacja wizualna transformacji przykładowej macierzy dla B_(s) = 2:
    $$\left[
    \begin{array}{cccccc}
        1 & 4 & 0 & 0 & 0\\ 
        0 & 2 & 3 & 0 & 0\\ 
        5 & 0 & 0 & 7 & 8\\ 
        0 & 6 & 0 & 8 & 0\\ 
    \end{array}
    \right]
    \rightarrow
    \left[
    \begin{array}{cccccc}
        1 & 4 & 0 & 0 & 0 & 0 \\ 
        0 & 2 & 3 & 0 & 0 & 0 \\ 
        5 & 0 & 0 & 7 & 8 & 0 \\ 
        0 & 6 & 0 & 8 & 0 & 0 \\ 
    \end{array}
    \right]
    \rightarrow
    \left[
    \begin{array}{cc|cc|cc}
        1 & 4 & 0 & 0 & 0 & 0 \\ 
        0 & 2 & 3 & 0 & 0 & 0 \\ 
        \hline
        5 & 0 & 0 & 7 & 8 & 0 \\ 
        0 & 6 & 0 & 8 & 0 & 0 \\ 
    \end{array}
    \right]$$

    $$A_{b} = \begin{bmatrix}
    A_{00} & A_{01} & A_{02} \\
    A_{10} & A_{11} & A_{12} \\
    \end{bmatrix}
    \rightarrow
    \begin{matrix}

    \begin{matrix}
    A_{00} = \begin{bmatrix}
    1 & 4 \\
    0 & 2 \\
    \end{bmatrix},
    A_{01} = \begin{bmatrix}
    0 & 0 \\
    3 & 0 \\
    \end{bmatrix},
    \end{matrix}

    \\

    \begin{matrix}
    A_{10} = \begin{bmatrix}
    5 & 0 \\
    0 & 6 \\
    \end{bmatrix},
    A_{11} = \begin{bmatrix}
    0 & 7 \\
    0 & 8 \\
    \end{bmatrix},
    A_{12} = \begin{bmatrix}
    8 & 0 \\
    0 & 0 \\
    \end{bmatrix}
    \end{matrix}

    \end{matrix}$$

    $$\begin{matrix}
    \text{floatdata} & = & \begin{bmatrix}
    A_{00} & A_{01} & A_{10} & A_{11} & A_{12} \\
    \end{bmatrix} \\
    \text{columnIndices} & = & \begin{bmatrix}
    0 & 1 & 0 & 1 & 2 \\
    \end{bmatrix} \\
    \text{rowOffsets} & = & \begin{bmatrix}
    0 & 2 & 5 \\
    \end{bmatrix} \\
    \end{matrix}$$



MIKRO-ARCHITEKTURA, INTERFEJS VULKAN I SHADERY OBLICZENIOWE


Mikro-architektura nowoczesnych procesorów graficznych

Podejście do architektury, którą mikroprocesory graficzne mają implementować i ulepszać z generacji na generację wyewoluowało z wyspecjalizowanego na generyczne. Początkowo ogólną ideą było stworzenie akceleratora posiadającego wyspecjalizowane jednostki, będące odpowiedzialne tylko za ściśle określone operacje. Jednostki podzielono na trzy poziomy, każdy kolejny poziom miał na celu realizację innej operacji: przetwarzanie wierzchołków geometrii, generowanie fragmentów i ich finalne połączenie. Próba odwzorowania teoretycznej abstrakcji grafiki trójwymiarowej w krzemie stworzyła skomplikowany i mało elastyczny mikro-procesor. Przykładowo, jeżeli dana aplikacja chce narysować mało wierzchołków, a jednocześnie wykonać skomplikowane operacje na wygenerowanych fragmentach, nie było możliwości wykorzystania krzemu przeznaczonego do przetwarzania geometrii do wykonywania obliczeń na wierzchołkach. Można podać odwrotny przykład, w którym aplikacja chce wykorzystać wiele wierzchołków, natomiast mieć proste obliczenia na wynikowych fragmentach. Wszystko, co wybiegało poza przewidzianą przez twórców architektury normę nie wykorzystywało krzemu w całości mimo tego, że surowa moc obliczeniowa w teorii była dostępna. Twórcy architektury również mieli problemy z optymalnym rozłożeniem ilości krzemu przeznaczonego dla poszczególnych kroków procesu.

Rozwiązaniem było stworzenie ogólnej jednostki, będącej w stanie wykonywać zadane obliczenia bez przywiązania do jakiejkolwiek abstrakcyjnej wizji. Wraz z premierą architektury _Tesla_ w mikroprocesorach firmy _NVIDIA_, wprowadzono pojęcie multi-procesora strumieniowego (ang. Stream Multiprocesor), w skrócie _SM_. Posiadał on 8 jednostek wykonawczych (ALU), obsługujących podstawowe operacje na 32-bitowych liczbach zmiennoprzecinkowych, 2 jednostki specjalnego przeznaczenia (SFU), pozwalające na obliczanie skomplikowanych funkcji, na przykład _sin_, _exp_ . Aby dostarczyć dane do rdzeni, _SM_ posiada pamięć podręczną instrukcji, pamięć współdzieloną pomiędzy jednostki wykonawcze, pamięć podręczną wartości stałych oraz kolejkę wątków do uruchomienia. Według taksonomii Flynna, architektura _Tesla_ zostałaby zaklasyfikowana w kontekście SIMD (Single Instruction Multiple Data) jako procesor tablicowy (ang. Array Processor), czyli jeden obiekt kontrolny sterujący daną ilością połączonych elementów obliczeniowych, które same w sobie są niezależne, (na przykład mają własne rejestry), natomiast wszystkie operują na podstawie komend wydanych przez obiekt kontrolny. Obecnie najczęściej ta klasyfikacja opisywana jest jako SIMT (Single Instruction Multiple Threads), nazwa ta została rozpowszechniona przez firmę NVIDIA. Zadania przypisywane są do kolejek wolnych _SM_ w grupach 32 wątków nazwanych _warp_’ami. Opróżnienie kolejki zajmowało 4 cykle, jeżeli wszystkie instrukcje mogą zostać wykonane na rdzeniach _ALU_. Dla operacji wymagających wykorzystania rdzeni _SFU_ wykonanie wszystkich przypisanych wątków trwa 16 cykli.

Najmniejszy logiczny blok adresowalny wewnątrz mikroprocesora, jakim jest _SM_, ma generyczną naturę, która sprawia, że w prosty sposób można zwiększyć moc obliczeniową mikro-procesora poprzez zwiększenie ich ilości znajdujących się w krzemie. Takie podejście pokrywało wszystkie możliwe przypadki, nieważne jak bardzo odbiegające od normy. Całość krzemu jest wykorzystywana, a to, jakie zadanie ma pełnić zostaje dynamicznie określone zależnie od typu pracy. W porównaniu do rdzenia procesora centralnego celem nie jest zwiększenie wydajności jednego wątku. Zmniejsza to potrzebę na implementowanie części spekulacyjnej procesora oraz dużych pamięci podręcznych. Ideą jest jak największa surowa moc obliczeniowa pożądana w takich dziedzinach jak algebra liniowa, metody numeryczne czy grafika komputerowa. Odblokowanie takich możliwości umożliwiło tworzenie o wiele bardziej skomplikowanych symulacji i tchnęło nowe życie w pole sztucznej inteligencji. Kolejne mikro-architektury budowały na koncepcie _SM_, zwiększając ich możliwości, moc oraz ilość dzięki postępom w litografii.


Interfejs Vulkan

Jednostka centralna komunikuje się z procesorem graficznym przy użyciu abstrakcyjnego interfejsu, który opisuje zestaw procedur oraz ich oczekiwany wynik działania. Sposób implementacji danego interfejsu zależy od sterownika graficznego. Idealny interfejs jest abstrakcyjny w takim stopniu, żeby pozwolić różnym producentom procesorów graficznych na elastyczne implementowanie procedur bez ścisłego powiązania z samą architekturą fizyczną. Dla użytkowników interfejs powinien dostarczać możliwie jak największej kontroli nad tym, co wykonuje procesor graficzny. Przykładowo, jeden z pierwszych interfejsów, _OpenGL_ opierał się na wywoływaniu komend, które zmieniały globalną maszynę stanu, a ta następnie była interpretowana przez sterownik graficzny. Wysokopoziomowa abstrakcja miała na celu pozwolenie użytkownikowi na ignorowanie wielu operacji dziejących się bez jego wiedzy. Mimo licznych zalet, rozwiązanie takie miało również swoje wady. Osoby doświadczone nie miały możliwości niskopoziomowej kontroli, przez co pole optymalizacji było ograniczone. W samej specyfikacji istniały miejsca, w których wynik działania danej komendy był niedoprecyzowany. Finalne zachowanie było zależne od implementacji, przez co ten sam program wykonany na procesorach graficznych dwóch różnych producentów mógł wykazywać różne wyniki.

Sfinalizowany w roku 2016 interfejs _Vulkan_ ma na celu zastąpienie interfejsu _OpenGL_. Zbudowany został na podstawach interfejsu _Mantle_, który został stworzony oraz następnie przekazany grupie _Khronos_ przez firmę _AMD_. W przeciwieństwie do swojego poprzednika, niskopoziomowa abstrakcja umożliwia wykorzystanie procesora graficznego w bardziej generyczny sposób. Aby to zrobić, użytkownikowi zostaje dostarczony zestaw procedur operujących na przesłanym przez niego stanie w poszczególnych obiektach. Odstąpienie od globalnego stanu umożliwiło wielowątkowe sterowanie procesorem graficznym, co przekłada się na zwiększoną wydajność w przypadkach, gdy procesor jest wąskim gardłem w programie. Wydajność zostaje również poprawiona poprzez ominięcie sprawdzania błędów przez sterownik graficzny podczas pracy programu, jest to zadaniem użytkownika, aby dostarczyć do sterownika poprawne dane. Na użytkowniku ciąży wiele odpowiedzialności, zostaje mu powierzone zarządzanie pamięcią oraz synchronizacją procesora graficznego. Wszystko to celem maksymalnego wykorzystania procesora graficznego, aby osiągnąć jak najwyższą wydajność. Doświadczony programista jest w stanie zarządzać dostępnymi mu zasobami na wcześniej niespotykaną skalę dokładności.

Posługiwanie się przez specyfikacje prostymi i kompatybilnymi z architekturą komputerów konceptami znacznie redukuje możliwość niesprecyzowania danego aspektu interfejsu. Twórcy sterowników graficznych mogą je znacznie uprościć, tym samym redukując ilość błędów i poprawiając wydajność. Zniesione zostaje również rozgraniczenie pomiędzy interfejsem dla mobilnych i konwencjonalnych procesorów graficznych. Poprzednio dla systemów wbudowanych został stworzony interfejs _OpenGL ES_, będący podzbiorem interfejsu _OpenGL_ dla komputerów stacjonarnych. Tworzy to sztuczny podział, w którym utrzymanie dwóch różnych systemów wymaga w najgorszym przypadku dwa razy więcej wysiłku. Podział ten nie istnieje dla _Vulkan_, ponieważ od początku celem było zunifikowanie wszystkich urządzeń i zmniejszenie liczby interfejsów do jednego. Dzisiaj ten sam interfejs wspierany jest w komputerach stacjonarnych, urządzeniach mobilnych, systemach wbudowanych i konsolach. Narzędzia stworzone do pracy z aplikacjami wykorzystującymi _Vulkan_ mogą zostać wykorzystane we wszystkich typach urządzeń.

Mimo, że grafika komputerowa była głównym wspieranym celem, podczas tworzeniu interfejsu przewidziano wykorzystanie procesora graficznego do innych zadań. Rozwijające się pole sztucznej inteligencji zaczęło polegać na mocy obliczeniowej procesorów graficznych do budowania coraz to większych modeli uzyskujących coraz to lepsze wyniki. _Vulkan_ przewiduje możliwość wykorzystania procesora graficznego do obliczeń naukowych, osiąga to poprzez tworzenie różnego typów potoków. Obok potoku graficznego istnieje potok obliczeniowy, który pozwala na uruchomienie wybranych shaderów obliczeniowych.


Shadery obliczeniowe

Shader to ogólnie przyjęta nazwa na program stworzony przez użytkownika, który ostatecznie zostanie uruchomiony na procesorze graficznym. Shaderem obliczeniowym jest program wielowątkowy, działający w modelu SIMT dokonujący arbitralnych obliczeń. Jednostka centralna żąda wywołania pewnej ilości grup shaderów, a ich ilość jest określona jako trójwymiarowa przestrzeń X × Y × Z. Ułatwia to wykonywanie obliczeń na problemach z natury wielowymiarowych. Przykładowo, ustawiając wymiar Z = 1 zostanie uruchomiona dwuwymiarowa grupa, którą można wykorzystać przy algorytmach działających na obrazach lub automatach komórkowych. Łączna liczba n_(SC) wszystkich uruchomionych shaderów obliczeniowych w danej inwokacji może zostać określona jako iloczyn wszystkich wymiarów n_(SC) = XYZ. Należy jednak rozgraniczyć grupę i pojedyncze wywołanie shadera. Ilość wywołań shaderów w pojedynczej grupie jest definiowane przez sam shader jako lokalny rozmiar shadera, który również jest trójwymiarową wartością X_(l) × Y_(l) × Z_(l).

Wszystkie wartości wejściowe i wyjściowe shadera są zdefiniowane przez użytkownika. Shadery mają dostęp do swojego identyfikatora grupy oraz lokalnego identyfikatora wewnątrz tej grupy. Wywołania shadera z tej samej grupy współdzielą identyfikator grupy, natomiast każdy z nich dostanie unikatowy lokalny identyfikator. Na podstawie tych identyfikatorów shader może określić, na jakich danych ma operować. Dane do i z shaderów są przenoszone poprzez sampler tekstur lub Shader Storage Buffer Object (_SSBO_). _SSBO_ są buforami przechowującymi dane w sekwencyjny sposób, których rozmiar może być dynamiczny, mają one niespójny model pamięci, to znaczy, że dane zapisane przez jeden wątek nie muszą być od razu widoczne przez drugi wątek. To samo zachodzi z zapisem, nie ma gwarancji, że dane zapisane przez jeden wątek nie zostaną nadpisane przez inny wątek przed trafieniem do pamięci głównej. Aby rozwiązać sytuację, w której więcej niż jeden wątek musi zapisać dane do tej samej komórki pamięci _SSBO_ wspierają atomiczne operacje na pamięci.

_Vulkan_ oczekuje, że wszystkie shadery będą przekazane do niego w formacie _SPIR-V_, jest to język pośredni przechowywany w formacie binarnym, stworzony na potrzeby obliczeń wielowątkowych i graficznych. Użycie języka pośredniego pozwala na tworzenie shaderów w różnych językach programowania, które należy jedynie sprowadzić do formy zgodnej ze specyfikacją _SPIR-V_. Językiem najczęściej wykorzystywanym jako wysokopoziomowa abstrakcja jest _GLSL_, używany wcześniej w _OpenGL_. Wykorzystanie formatu binarnego w przeciwieństwie do _OpenGL_, gdzie cały kod _GLSL_ był przechowany jako ciąg czytelnych znaków, posiada wiele zalet. Największą z nich jest uproszczenie sterownika graficznego, który nie musi implementować całego kompilatora języka o podobnym stopniu skomplikowania, co język C. Konwersja odbywająca się w sterowniku jest prostsza i o wiele bardziej wydajna, ponieważ zbędna praca została wykonana wcześniej podczas konwersji na format _SPIR-V_. Zmniejsza to czas potrzebny na przygotowanie _pipeline_’u, przez co aplikacje mają większą swobodę w wykorzystywaniu większej ilości shaderów. Format binarny zajmuje również mniej miejsca na dysku oraz utrudnia inżynierię wsteczną własnościowych shaderów w publicznych aplikacjach.



IMPLEMENTACJA


W tym rozdziale opisana jest implementacja uruchomienia algorytmów mnożenia macierzy rzadkiej przez wektor na procesorze graficznym. Pierwszy podrozdział omawia opracowany sposób na komunikację z procesorem graficznym przy wykorzystaniu interfejsu _Vulkan_. Drugi przedstawia sposób przechowywania danego formatu macierzy rzadkiej, konwersji na ten format oraz shader obliczeniowy, którego zadaniem jest obliczenie wyniku mnożenia macierz - wektor dla tego formatu.


Komunikacja z procesorem graficznym

Aby rozpocząć komunikację z procesorem graficznym należy stworzyć obiekty skonfigurowane w taki sposób, w jaki zamierzamy ich używać. Inicjalizacja stanu początkowego w interfejsie Vulkan sprowadza się do stworzenia instancji, wybrania fizycznego urządzenia oraz na jego podstawie stworzenia urządzenia logicznego, stworzenia puli zasobów, z których korzystać będą obiekty komend i kwerend. Podczas tworzenia instancji użytkownik ma możliwość podania tablicy z warstwami, które mają zostać włączone oraz rozszerzeń, które mają zostać dodane do danej instancji. Warstwy to rozwiązanie problemu debugowania programów napisanych przy użyciu interfejsu _Vulkan_. Ponieważ sterownik graficzny nie sprawdza poprawności przesłanych do niego danych, znajdowanie źródeł błędów jest o wiele trudniejsze. Rozwiązaniem tego problemu są warstwy, czyli dodatkowy kod wykonywany dookoła wywołania funkcji. Takie podejście można opisać jako wzorzec projektowy dekorator. Istnieje wiele warstw, które pełnią różne funkcje, przykładowo dodając warstwę zapisującą kiedy dana funkcja została wywołana, możemy stworzyć graf wywołań w danym programie. Najbardziej pomocną warstwą podczas tworzenia aplikacji od nowa jest warstwa walidująca. Będzie ona sprawdzać poprawność przesłanych danych względem tego, co mówi specyfikacja. Niezgodności z nią są wypisane na terminalu, towarzyszy temu wytłumaczenie co dokładnie jest niezgodne ze specyfikacją. Warstwa walidująca upewnia się, że program będzie działać tak samo niezależnie od wersji sterownika lub typu procesora graficznego. Niezgodność nie oznacza, że dany kod będzie skutkował błędnym wynikiem, natomiast nie ma gwarancji, że wynik ten nie zmieni się, jeżeli domyślny stan będzie się różnić w innym środowisku pracy. Wsparcie danej warstwy jest opcjonalne, przykładowo warstwy potrzebne tylko podczas tworzenia oprogramowania nie muszą być załączane razem z plikami programu, co zmniejsza jego rozmiar. Aby sprawdzić czy dana warstwa jest w danym środowisku wspierana, należy wykorzystać funkcję _vkEnumerateInstanceLayerProperties_. Kod [isValidationLayerSupported] przedstawia wykorzystanie tej funkcji do sprawdzenia czy przesłana nazwa warstwy walidującej znajduje się w wspieranych warstwach. Warto zauważyć podejście do rozwiązania problemu dynamicznej ilości danych na granicy interfejsu jakie wybrał Vulkan, funkcja przyjmuje dwa argumenty, z czego jeden to wskaźnik na liczbę całkowitą, a drugi to wskaźnik na tablicę elementów wyjściowych. Funkcja posiada dwustanowe zachowanie, jeżeli wskaźnik na tablicę elementów wyjściowych równy jest _NULL_ to liczba wszystkich dostępnych warstw jest wpisana przez wskaźnik zmiennej określającej ilość elementów, funkcja nie wykonuje w tym stanie żadnych innych operacji. Po wyjściu z tej funkcji użytkownik wie, ile elementów musi dynamicznie zaalokować, żeby pomieścić wszystkie dostępne warstwy. W drugim stanie, jeżeli wskaźnik na tablicę elementów wyjściowych jest niezerowy, to odczytywana jest przez wskaźnik liczba ilości elementów dostępnych w tablicy wyjściowej oraz pod koniec zostaje nadpisana faktyczną ilością elementów wpisanych. W tablicy wyjściowej użytkownik ma dostęp do właściwości warstw, takich jak ich nazwa, wersja specyfikacji, wersja implementacji oraz krótki opis, jeżeli znajduje się w niej warstwa o takiej samej nazwie jaka została przesłana do funkcji, zostaje zwrócona wartość boolowska wskazująca na prawdę lub fałsz w przypadku braku szukanej warstwy.

Tworzenie instancji odbywa się przy użyciu funkcji _vkCreateInstance_, cechy charakterystyczne jej interfejsu są powielone we wszystkich pozostałych procedurach zdefiniowanych w _Vulkan_. Funkcja zawsze zwraca obiekt typu _VkResult_, który jest enumeracją wszystkich możliwych rezultatów wykonania. Jest to podstawowa forma raportowania błędów, pomyślnie wykonana funkcja zawsze zwróci wartość _VK_SUCCESS_. Dla porównania, OpenGL zwraca kod błędu poprzez wykorzystanie osobnej funkcji _glGetError_, a takie podejście wymaga globalnego stanu, który gorzej współpracuje z wieloma wątkami chcącymi raportować błędy. Architektura _Vulkan_ brała pod uwagę raportowanie błędów od samego początku tworzenia, kod błędu zwrócony jako wynik funkcji nie wymaga globalnego stanu, przez co wielowątkowe wykorzystanie _Vulkan_ jest możliwe. Znany jest problem, w którym niemożliwe jest rozłożenie pracy podczas korzystania z OpenGL na wiele wątków, a przez to jeden wątek staje się mocniej obciążony niż reszta podczas wysyłania danych na kolejkę procesora graficznego. Stanowi to problem w aplikacjach wykorzystujących zaawansowaną grafikę trójwymiarową, głównie w grach, ponieważ w obecnych czasach prędkość pojedynczego rdzenia jednostki centralnej rośnie o wiele wolnej niż ich ilość. Niewykorzystanie możliwości wielowątkowych dzisiejszych jednostek centralnych nakłada ograniczenia na rzeczy, które są możliwe do wykonania, odejście od globalnego stanu to jeden z kroków podjętych celem wspierania pracy wielowątkowej przez _Vulkan_.

Funkcja tworząca instancję przyjmuje trzy argumenty, które również ukazują jakie rozwiązania zostały przyjęte podczas tworzenia samego interfejsu, argumenty to następująco: wskaźnik na obiekt opisujący jak stworzyć instancję, wskaźnik na obiekt opisujący jak zarządzać pamięcią po stronie jednostki centralnej oraz obiekt wyjściowy samej instancji. Konfigurację tworzonego obiektu przechowuje się w dostarczonych do tego strukturach, pozwala to na zmniejszenie ilości parametrów przesyłanych do każdej z funkcji upraszczając jej wykorzystanie. Vulkan udostępnia możliwość sterowania alokacją pamięci po stronie jednostki centralnej programiście, wykorzystuje do tego obiekt struktury _VkAllocationCallbacks_, w którym znajdują się wskaźniki na funkcje alokujące i zwalniające pamięć. Częstym jest tworzenie niestandardowych obiektów zarządzających alokacją pamięci, celem zwiększenia wydajności programu oraz zmniejszenie szansy na wyciek pamięci. Jeżeli zamiast wskaźnika na obiekt alokatora zostanie przesłana wartość _NULL_, _Vulkan_ wykorzysta domyślny interfejs _malloc_ i _free_ do zarządzania pamięcią. Ostatnim argumentem w funkcjach tworzących jest zawsze wskaźnik na obiekt tworzony, do którego będzie wpisany wynikowy obiekt, ponieważ wartość zwracana przez funkcję jest już zawsze wykorzystana do zwracania kodu błędu. Funkcja ukazana w kodzie [createInstance] tworzy instancję _Vulkan_ z załączoną warstwą walidującą jeżeli taka jest dostępna. Konfiguracja instancji umożliwia podania informacji na temat aplikacji, takich jak jej nazwa, wersja, nazwa silnika oraz jego wersja i finalnie wersja API Vulkan. Dane te umożliwiają twórcom sterowników graficznych na optymalizację zachowania najpopularniejszych programów, na przykład silników do tworzenia gier, takich jak Unity czy Unreal Engine. Każda struktura w Vulkan posiada pole _sType_ i odpowiadającą tej strukturze wartość enumeracyjną, pozwala to na dowolne rozszerzanie pewnych struktur poprzez tworzenie listy połączonej, w których to jaka struktura znajduje się w danym elemencie listy określone jest przez pole _sType_. Po stworzeniu obiektu struktury _VkApplicationInfo_, jego adres pamięci zostaje zapisany w finalnym obiekcie konfigurującym tworzenie instancji, ten jest rozszerzony o warstwą walidującą, jeżeli taka jest wspierana. Wywołanie ostatecznej funkcji owinięte jest w makro sprawdzające, czy zwrócony kod błędu równy jest _VK_SUCCESS_.

Wybór fizycznego urządzenia odbywa się poprzez wysłanie zapytania do interfejsu o enumerację wszystkich obecnych urządzeń w tym systemie. Użytkownik następnie dokonuje wyboru, który procesor graficzny spełnia jego wymagania. Może dokonywać zapytań o to, jakie funkcjonalności wspiera dane urządzenie oraz jakie są jego specyfikacje. Nie można oczekiwać, że w systemie zawsze będzie znajdować się tylko jeden procesor graficzny. Przykładami systemów posiadających więcej niż jeden procesor graficzny mogą być laptopy z procesorem graficznym dedykowanym oraz zintegrowanym z jednostką centralną lub serwery, na których często znajduje się wiele takich samych procesorów graficznych współpracujących ze sobą. W kodzie [findPhysicalDevice] dokonywana jest dokładnie ta operacja, z założeniem, iż wybrane zostanie zawsze pierwsze zwrócone urządzenie fizyczne.

Na podstawie urządzenia fizycznego tworzone jest urządzenie logiczne, wymaga ono opisania z jakich kolejek będzie korzystać program. Przykładowo, program graficzny będzie korzystać z kolejki wspierającej operacje graficzne, natomiast program uruchamiający tylko i wyłącznie shadery obliczeniowe będzie korzystać z kolejki wspierającej arbitralne obliczenia. W funkcji [createDevice] dane te są wpisywane do obiektu typu _VkDeviceQueueCreateInfo_, dla tego programu stworzona zostanie jedna kolejka, z priorytetem równym jeden, ten może przyjąć dowolną wartość zmiennoprzecinkową pomiędzy zero a jeden dla każdej tworzonej kolejki. Stworzone kolejki będą typu, który wskazuje indeks rodziny kolejki, ten został pobrany poprzez enumerację wszystkich kolejek na danym urządzeniu fizycznym przy użyciu _vkGetPhysicalDeviceQueueFamilyProperties_ i wybraniu tej, która ma ustawioną flagę _VK_QUEUE_COMPUTE_BIT_.

Następnie użytkownik ma możliwość włączenia danych specjalnych funkcji procesora graficznego, przykładowo obsługa typu zmiennoprzecinkowego podwójnej precyzji, która domyślnie jest wyłączona. Dodatkowo, istnieje możliwość zdefiniowania rozszerzeń, które mają zostać włączone, rozszerzeniami są nowe niezdefiniowane przez specyfikacje komendy, struktury i wartości enumeracyjne. Przykładem jest rozszerzenie _VK_NV_COOPERATIVE_MATRIX_, pozwalające użytkownikowi na wykorzystanie rdzeni tensorowych, znajdujących się tylko na urządzeniach najnowszych generacji od NVIDIA. Wspieranie takiej funkcjonalności nie może być dodane przez specyfikację, ponieważ nie wszystkie procesory graficzne będą wspierać to rozszerzenie. Mimo wszystko posiadanie rozszerzeń do urządzenia pozwala interfejsowi _Vulkan_ być bardziej elastycznym w wspieraniu wielu pofragmentowanych rozwiązań. Ponieważ program wymaga wykorzystania operacji atomicznych dla wybranych algorytmów należy je włączyć poprzez dodanie rozszerzenia _VK_EXT_shader_atomic_float_. Nazwa rozszerzenia zostaje dodana do tablicy włączonych rozszerzeń, a konfiguracja tego rozszerzenia zdefiniowana przez strukturę _VkPhysicalDeviceShaderAtomicFloatFeaturesEXT_, w której włączona jest atomiczna operacja dodawania zostaje dodana do pola _pNext_, które służy do rozszerzenia tej struktury przy użyciu listy połączonej. Po skonfigurowaniu tych opcji może zostać stworzone urządzenie logiczne, przy jego pomocy będzie wykonywana cała komunikacja z procesorem graficznym. Jako ostatni pobierany jest logiczny odnośnik do kolejki, na którą będzie wysyłana praca do wykonania przez procesor graficzny.

Ostatni krok w ogólnej inicjalizacji to stworzenie dwóch pul pamięci dla komend i kwerend. Podejście takie pozwala na posiadanie tylko jednego określonego miejsca, w którym znajduje się pamięć danej rzeczy, tym samym zwiększając lokalność pamięci. Funkcje odpowiedzialne za stworzenie obu tych obiektów przedstawione są w kodzie [commandAndPoolCreation]. Stworzenie puli dla komend wymaga podania indeksu kolejki na urządzeniu fizycznym, do której będą wysyłane komendy zaalokowane w tej puli. Pula dla kwerend natomiast wymaga logicznego urządzenia, na którym będą wykonywane kwerendy, ich typ oraz maksymalna ilość.

Na podstawie tego globalnego stanu zostają utworzone dodatkowe obiekty, będące odpowiedzialne za uruchomienie poszczególnych shaderów obliczeniowych dla danego formatu przechowywania macierzy. Dla każdego formatu są to te same obiekty tworzone w tej samej kolejności, natomiast różnią się na przykład rozmiarem lub ilością. Zbiór wszystkich obiektów potrzebnych do komunikacji z procesorem graficznym celem wywołania poszczególnego shadera dla wybranego typu macierzy nie będących stanem globalnym od tego miejsca nazwano scenariuszem. Każdy scenariusz zawierał następuje obiekty: pary buforów i pamięci, pulę deskryptorów, ich ułożenie oraz zbiór, definicję potoku oraz bufor komend. Przykładowa struktura opisująca scenariusz znajduje się w kodzie [BSRScenario].

W uproszczeniu, bufor jest wglądem do pamięci w zdefiniowanym zakresie, natomiast pamięć jest obiektem przy pomocy którego zarządzamy czasem życia danej alokacji pamięci. Takie rozwiązanie pozwala na stworzenie wielu różnych zmieniających się wglądów do zaalokowanej pamięci bez potrzeby jej ciągłej realokacji. Grupy bufora i pamięci zawsze były tworzone w parze, jedna reprezentowała pamięć, do której jednostka centralna ma dostęp natomiast druga reprezentowała pamięć lokalną dla procesora graficznego. Jest to wymagane, ponieważ jednostka centralna nie może bezpośrednio dokonywać arbitralnych operacji na lokalnej pamięci procesora graficznego. Bufor wykorzystywany do przepisywania pamięci z jednostki centralnej do pamięci procesora graficznego nazywa się buforem przestojowym (ang. staging buffer). Zanim bufor zostanie stworzony należy określić jego rozmiar, sposób współdzielenia pomiędzy kolejkami i to, w jaki sposób będzie wykorzystywany, np. dla bufora przestojowego wykorzystywana jest możliwość przechowywania danych oraz bycie źródłem podczas transferu. Po stworzeniu bufora należy dokonać kwerendy celem określenia wyrównanego rozmiaru pamięci oraz jakie typy pamięci, które posiada urządzenie będą wspierać wszystkie zdefiniowane sposoby wykorzystywania. Zaalokowanie pamięci wymaga odpytania urządzenia jakie posiada typy pamięci oraz w jakich kopcach się znajdują. Wybór typu pamięci sprowadza się do tego, czy istnieje pamięć, będąca w stanie obsłużyć wszystkie wymagania bufora i czy jest wystarczająco blisko pamięci samego rdzenia mikroprocesora graficznego. Po wskazaniu wyrównanej ilości pamięci do zaalokowania oraz który typ pamięci ma zostać wykorzystany zostaje stworzony obiekt pamięci. Ten finalnie może zostać przypisany do bufora. Funkcja odpowiedzialna za wykonanie tych wszystkich operacji znajduje się w kodzie [createBuffer]. Zakłada ona, że zawsze tylko jedna kolejka będzie miała dostęp do bufora dlatego _sharingMode_ ustawiony jest na wartość wskazującą wyłączony dostęp.

Operacje na pamięci przez jednostkę centralną w buforach wspierających tę operację dokonywane są poprzez zmapowanie tej pamięci do przestrzeni adresowej danego programu. Po tym, procesor ma dostęp do wszystkich bajtów w sposób równoważny pamięci zaalokowanej na przykład przez funkcję _malloc_. Program ma obowiązek usunąć mapowanie pamięci przed wykorzystaniem jej do komunikacji z procesorem graficznym. Przykładowa funkcja w kodzie [inVecToSSBO] przy użyciu funkcji _vkMapMemory_ i _vkUnmapMemory_ przenosi zawartość wektora do pamięci bufora przestojowego.

Zaprzęgnięcie procesora graficznego do faktycznego wykonywania pracy wymaga wysłania bufora z nagranymi komendami na daną kolejkę. Aby nagrać komendy potrzebne jest miejsce, które będzie zapisywać liniowy ciąg wywołanych komend, jest nim bufor komend, a do jego alokacji należy wskazać na pulę komend, która będzie zarządzać stworzonymi buforami komend. Taki bufor komend jest rozpoczynany i od tego momentu wszystkie wywołane procedury będące komendą są liniowo dodawane do tego bufora komend, aż do zakończenia jego nagrywania. Gotowy bufor zostaje wysłany na kolejkę, która ma go wykonać, w przypadku implementowanego programu jest to kolejka obliczeniowa. Celem tworzonego programu jest zachowanie synchroniczności podczas komunikacji z procesorem graficznym, więc zaraz po zakolejkowaniu operacji program czeka, aż kolejka będzie bezczynna, co będzie wskazywać na wykonanie bufora komend. Funkcja przedstawiona w kodzie [copyStagingBufferToDevice] przy wykorzystaniu buforów komend kopiuje dane z bufora przestojowego do bufora znajdującego się w pamięci globalnej procesora graficznego. Tworząc bufor komend możliwe jest określenie dwóch poziomów, bufor główny może wykonać nagrany bufor drugorzędny oraz samemu być przesłanym na kolejkę. Bufor drugorzędny może być jedynie wykonany w kontekście bufora głównego oraz nie może być przesłany na kolejkę. Ponieważ dla tego zastosowania bufor zostaje zwolniony po jego wykonaniu, dodatkowo przesłana jest flaga w obiekcie struktury _VkCommandBufferBeginInfo_ wskazując na fakt, iż bufor ten zostanie uruchomiony tylko raz. Używając komendy _vkCmdCopyBuffer_, do której argumentem jest obiekt określający cały rozmiar bufora bez żadnego przesunięcia ani w buforze źródłowym ani w buforze docelowym, dokonywana jest kopia bufora. Nagrany bufor komend zostaje przesłany na kolejkę funkcją _vkQueueSubmit_ oraz przy użyciu _vkQueueWaitIdle_ program po stronie jednostki centralnej czeka na zakończenie operacji.

Pula deskryptorów pełni taką samą rolę jak pula komend i kwerend, alokacje deskryptorów są lokalizowane do danej puli ułatwiając zarządzanie. W kodzie [createDescriptorPool] przedstawiona jest funkcja, tworząca pulę deskryptorów, z której będzie można zaalokować jeden deskryptor typu _VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_. W konfiguracji tworzenia zostaje przesłana flaga pozwalająca na zwalnianie zaalokowanych deskryptorów z powrotem do puli, bez tej flagi jedyne operacje jakie są dostępne to wykorzystanie puli do alokacji i jej zrestartowanie. Ponieważ konfiguracja przyjmuje tablicę rozmiarów do zaalokowania, jedna pula może służyć jako globalna pula, z której alokowane są deskryptory różnych typów.

Deskryptor reprezentuje zasób dostępny shaderowi, na przykład bufor lub sampler tekstur. Zdefiniowanie deskryptora wymaga stworzenia obiektu zestawu deskryptorów, a to z kolei wymaga opisania układu deskryptorów w zestawie poprzez stworzenie obiektu układu zestawu deskryptorów. Funkcja [createConsecutiveDescriptorSetLayout] tworzy układ, w którym każdy deskryptor będzie następować po sobie, określamy indeks w zestawie, pod którym ten deskryptor będzie dostępny, jego typ oraz ilość, a gdy ta jest większa niż jeden umożliwia to stworzenie tablicy obiektów, na przykład takich jak samplery tekstur w shaderze. Różnica pomiędzy ilością deskryptorów w danym powiązaniu została przedstawiona na rysunku [descriptorCount].

Na podstawie jednego lub większej ilości układów zestawu deskryptorów funkcja [createDescriptorSet] tworzy obiekt zestawu deskryptorów, który obecnie jest tylko sposobem interpretacji podłączonych zasobów, natomiast nie posiada żadnych zasobów powiązanych ze sobą.

Przypisanie buforów odbywa się poprzez aktualizację zestawu deskryptorów, wymagane informacje to: który zestaw deskryptorów jest modyfikowany, który indeks w tym zestawie oraz ilość deskryptorów w tym indeksie, jakie należy zaktualizować. Sam zasób jest określany przez jeden z trzech różnych wskaźników na obrazy, bufory lub określony zakres bufora, dla buforów określany jest identyfikator bufora, przesunięcie względem początku oraz rozmiar, jaki ma być zmapowany. Ilość deskryptorów określa ilość elementów znajdujących się pod jednym z tych trzech wskaźników, to który z nich będzie wybrany określa typ deskryptora. Funkcja przypisująca bufory do deskryptorów przy pomocy funkcji _vkUpdateDescriptorSets_ przedstawiona jest w kodzie [bindDescriptorSetWithBuffers], jako parametry wejściowe przyjmuje buforów i przesunięcia w pamięci do nich i przypisuje je do układu deskryptorów stworzonego przez funkcję w kodzie [createConsecutiveDescriptorSetLayout].

Tak stworzony i zaktualizowany z przypisanymi buforami zestaw deskryptorów może następnie być wykorzystany podczas tworzenia potoku obliczeniowego. Będzie on uruchamiał dany shader, więc stworzony zostaje moduł shadera poprzez wykorzystanie danych binarnych w formacie SPIR-V. Następnie stworzony zostaje układu potoku, który wymaga podania układu deskryptorów oraz opcjonalnie zestawu stałych, które mają zostać przesłane do shadera. Ostatnimi informacjami do określenia to struktura opisująca etap potoku, posiada ona informacje o shaderze, takie jak jego moduł, nazwa funkcji wejściowej i typ etapu, w tym przypadku jest to etap obliczeniowy. Przy pomocy tych informacji zostaje stworzony potok obliczeniowy, który hermetyzuje sposób uruchomienia danego shadera i informacji z nim związanych. Funkcja przedstawiona w kodzie [createComputePipeline] jest odpowiedzialna za wszystkie wyżej wymienione kroki, jej rezultatem jest układ potoku zwierający dane o sposobie ułożenia deskryptorów i zestawie stałych oraz sam obiekt opisujący potok, który opisuje etap potoku oraz shader, który zostanie uruchomiony.

Aby go uruchomić należy stworzyć nowy bufor komend, rozpocząć jego nagrywanie i wywołać następujące komendy: przypisanie potoku, przypisanie zestawu deskryptorów, zrestartowanie puli kwerend, wpisanie obecnego znacznika czasowego do puli kwerend, wywołanie X × Y × Z grup inwokujących shader z tego potoku oraz wpisanego drugiego znacznika czasowego po zakończonych inwokacjach shadera, po czym nagrywanie bufora zostaje zakończone. Funkcja [createCommandBuffer] tworzy i nagrywa taki bufor komend na podstawie przesłanego obiektu potoku, zestawu deskryptorów oraz ilości grup, które mają być wywołane podczas uruchomienia. Tak nagrany bufor komend zostaje przesłany na kolejkę obliczeniową urządzenia, celem jego wykonania. Gdy kolejka przejdzie w stan bezczynności wszystkie komendy zostały wykonane, tak samo jak w przypadku funkcji [copyStagingBufferToDevice]. Przy użyciu obiektu puli kwerend pobierane zostają dwa znaczniki czasowe, a różnica pomiędzy nimi opisuje czas potrzebny na wykonanie tego shadera dla użytych danych.


Implementacja mnożenia macierz - wektor dla każdego z formatów 

Rozdział ten przedstawia sposób przechowywania w kodzie każdej z macierzy i shader wykorzystujący dany format do obliczenia iloczynu macierz-wektor.

Format COO

Kod [coo_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie COO.

Shader ukazany w kodzie [coo_shader] oblicza wynik mnożenia macierzy w formacie COO z wektorem. Przyjmuje cztery bufory wejściowe i jeden wyjściowy. Pierwsze trzy opisują kolejno: nagłówek macierzy, tablicę wartości, kolumn i rzędów elementów. Czwarta jest tablicą traktowaną jako wejściowy wektor, natomiast piąta jest wektorem wyjściowym. Każda inwokacja shadera określa swój globalny identyfikator jako dostarczona przez shader zmienna _gl_GlobalInvocationID.x_. Zmienna ta jest określona na podstawie identyfikatora grupy, lokalnego identyfikatora wątku wewnątrz grupy oraz rozmiaru lokalnej grupy. Ta ustawiona jest na wartość równą 32, aby być kompatybilna z rozmiarem _warp_’u, czyli najmniejszej jednostki przydzielenia pracy do _SM_. Globalny identyfikator służy jako indeks do określenia, jaką pracę ma wykonać każdy z wątków. Jeżeli indeks jest większy niż liczba wszystkich elementów wątek ten nie wykonuje żadnej pracy. W przeciwnym przypadku, wątek pobiera rząd oraz kolumnę elementu znajdującego się pod tym indeksem. Określa iloczyn wartości elementu z wartością w wejściowym wektorze, znajdującym się pod indeksem kolumny elementu. Następnie atomicznie dodaje go do wartości wektora wyjściowego, znajdującej się pod indeksem rzędu elementu. Atomiczna operacja wymagana jest ze względu na fakt, iż wątek ten nie ma wyłącznego dostępu do zapisu w tej komórce. Inne wątki w tym samym czasie mogą chcieć zapisać do tego samego miejsca, co skutkuje wyścigiem danych.

Format CSR

Kod [csr_struct] przedstawia strukturę będąca odpowiedzialna za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie CSR.

Shader ukazany w kodzie [csr_shader] oblicza wynik mnożenia macierzy w formacie CSR z wektorem. Bufory wejściowe są takie same jak w przypadku macierzy COO. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia. Jeżeli indeks jest większy niż liczba wszystkich rzędów wątek ten nie wykonuje żadnej pracy. W przeciwnym wypadku pobiera przesunięcie do tablic _floatdata_ i _columnIndex_, pod którym zaczynają się elementy dla tego rzędu. Na podstawie tablicy _rowOffsets_ ustala również ilość elementów niezerowych w tym rzędzie jako różnica przesunięcia następnego rzędu a rzędu obecnego. Fakt, iż długość tablicy _rowOffsets_ jest o jeden większa niż liczba rzędów, a ostatni element równy jest liczbie wszystkich elementów niezerowych pozwala na uniknięcie potrzeby wykorzystania specjalnego wyjątku, w którym dla ostatniego rzędu wykorzystywana jest wartość _elementNum_. Takie uproszczenie kodu pozwala mu na wyższą wydajność. Shader następnie, iterując po wszystkich niezerowych elementach, do lokalnej zmiennej _prod_ sumuje wszystkie iloczyny wartości elementów występujących w tym rzędzie. Ponieważ każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek. Usuwa to potrzebę bazowania na operacjach atomicznych, co przyśpiesza wykonanie shadera.

Format CSC

Kod [csc_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie CSC.

Shader ukazany w kodzie [csc_shader] oblicza wynik mnożenia macierzy w formacie CSC z wektorem. Bufory wejściowe są takie same jak w przypadku macierzy COO. Globalny identyfikator traktowany jest jako indeks kolumny, na którym mają zostać wykonane obliczenia. Jeżeli indeks jest większy niż liczba wszystkich rzędów kolumn, ten nie wykonuje żadnej pracy. W przeciwnym wypadku pobiera przesunięcie do tablic _floatdata_ i _rowIndex_, pod którym zaczynają się elementy dla tej kolumny. Na podstawie tablicy _columnOffsets_ ustala również ilość elementów niezerowych w tej kolumnie jako różnica przesunięcia następnej kolumny, a kolumny obecnej. Shader następnie, iterując po wszystkich niezerowych elementach, oblicza produkt pomiędzy wektorem , a danym elementem macierzy w tej kolumnie. Ze względu na przechodzenie po kolumnach zamiast po rzędach dana inwokacja shadera nie gwarantuje wyłączności do danej komórki wektora wyjściowego. Uniknięcie wyścigu danych wymaga wykorzystania atomicznej operacji dodawania.

Format ELL

Kod [ell_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie ELL.

Shader ukazany w kodzie [ell_shader] oblicza wynik mnożenia macierzy w formacie ELL z wektorem. Bufory wejściowe są podobne jak w przypadku macierzy COO, natomiast shader nie wymaga tablicy określającej rząd danego elementu i dodatkowo w nagłówku przesłana zostaje wartość P. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia. Jeżeli indeks jest większy niż liczba wszystkich rzędów wątek ten nie wykonuje żadnej pracy. W przeciwnym wypadku oblicza przesunięcie do tablic _floatdata_ i _columnIndices_, pod którym zaczynają się elementy dla tego rzędu. Następnie iterując w pętli do teoretycznego maksymalnego indeksu P, określany jest indeks elementu w obu tablicach. Jeżeli dla tego elementu wartość w _columnIndices_ wskazuje na brak danych, praca tego wątku zostaje przerwana. W przeciwnym przypadku, obliczony zostaje produkt, który jest sumowany do zmiennej lokalnej _prod_, która pod koniec zostaje wpisana do wektora wyjściowego. Każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek bez potrzeby wykorzystania operacji atomicznych.

Format SELL

Kod [sell_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie SELL.

Shader ukazany w kodzie [sell_shader] oblicza wynik mnożenia macierzy w formacie SELL z wektorem. Bufory wejściowe są identyczne jak w przypadku macierzy CSR, dodatkowo w zmiennej C nagłówek zawiera wysokość paska dla tej macierzy. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia. Jeżeli indeks ten jest większy niż liczba wszystkich rzędów wątek, ten nie wykonuje żadnej pracy. W przeciwnym wypadku obliczony zostaje indeks paska oraz indeks rzędu wewnątrz paska na podstawie globalnego indeksu rzędu i wartości C, wartość ta służy też do określenia ilości kolumn w tym pasku przy wykorzystaniu tablicy _rowOffsets_, jako różnica przesunięcia następnego paska, a paska obecnego podzielona przez wartość C. Pobrane zostaje również przesunięcie do tablic _floatdata_ i _columnIndex_, pod którym zaczynają się elementy dla tego paska. Wartości pasków przechowywane są kolumnowo, aby umożliwić procesorowi graficznemu łączenie dostępów do pamięci pomiędzy wątkami, ze względu na to, pierwszy element należący do danego wątku to przesunięcie w pamięci do obecnego paska plus indeks rzędu wewnątrz paska. Iterując przez wszystkie kolumny w pasku, do zmiennej lokalnej _prod_ sumowane zostaje iloczyn elementu macierzy z elementem wektora wejściowego. Aby uniknąć operacji warunkowej sprawdzającej obecność danych w elemencie, pod uwagę brane są wszystkie komórki macierzy wejściowej. W miejscach gdzie nie ma danych znajduje się zero, które podczas mnożenia nie produkuje wartości wypływających na wynik ostateczny. Każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek bez potrzeby wykorzystania operacji atomicznych.

Format BSR

Kod [bsr_struct] przedstawia strukturę odpowiedzialną za przechowywanie danych potrzebnych do opisania macierzy rzadkiej w formacie BSR.

Shader ukazany w kodzie [bsr_shader] oblicza wynik mnożenia macierzy w formacie BSR z wektorem. Bufory wejściowe są identyczne jak w przypadku macierzy CSR. Globalny identyfikator traktowany jest jako indeks rzędu, na którym mają zostać wykonane obliczenia, na jego podstawie obliczany jest indeks rzędu blokowego i indeks rzędu wewnątrz bloku. Jeżeli indeks rzędu blokowego jest większy niż liczba wszystkich rzędów blokowych lub indeks rzędu wewnątrz bloku jest większy niż rozmiar bloku, to wątek ten nie wykonuje żadnej pracy. W przeciwnym wypadku pobiera przesunięcie do tablic _floatdata_ i _columnIndex_, pod którym zaczynają się elementy dla tego rzędu blokowego. Na podstawie tablicy _rowOffsets_ ustalona zostaje ilość bloków niezerowych w tym rzędzie blokowym jako różnica przesunięcia następnego rzędu blokowego a rzędu obecnego. Iterując przez wszystkie kolumny blokowe, obliczane jest przesunięcie dla tego bloku i pobierana zostaje blokowa wartość kolumny tego bloku. W mniejszej pętli przechodzącej przez każdą kolumnę w bloku, która znajduje się na przypisanym temu wątkowi rzędzie, do zmiennej lokalnej _prod_ sumowany zostaje iloczyn elementów macierzy z elementem wektora wejściowego. Każdy wątek odpowiedzialny jest za unikatowy rząd, dane miejsce w pamięci wyjściowej jest zapisywane tylko przez jeden wątek bez potrzeby wykorzystania operacji atomicznych.



WYNIKI


W tym rozdziale opisana jest metodologia testowania wydajności algorytmów mnożenia macierzy rzadkiej z wektorem dla wartości pojedynczej precyzji (_SpMV_) oraz dokonana jest analiza uzyskanych wyników.

System wykorzystany do przeprowadzenia testów wydajności wyposażony był w procesor graficzny NVIDIA RTX 3060 (GA106) w konfiguracji 130W, działający pod sterownikiem w wersji 528.24. Systemem operacyjnym był Windows 11 w wersji 22H2, kompilator _glslc_ w wersji v2021.2 oraz VulkanSDK w wersji 1.2.182.0. Na potrzeby testów wykorzystano pięć macierzy: BEAFLW, DENSE2, BCSSTK32, SCIRCUIT i GA41AS41H72. Każda z nich reprezentuje różne cechy macierzy rzadkich: rozmiar, zagęszczenie, rozpiętość wartości w komórkach i sposób rozmieszczenia elementów. Każdy algorytm dla danego formatu uruchamiany był 1000 razy, celem zdobycia średniego czasu wykonania danej operacji.

BEAFLW ma wymiar 497 × 507, z czego 21.193% jest elementami niezerowymi, rozkład przestawiony na rysunku [beaflw_matrix_plot] wykazuje znikome skumulowanie względem przekątnej. [Rozkład w macierzy BEAFLW]

[beaflw_matrix_plot]

DENSE2 ma wymiar 2000 × 2000, z czego 100% elementów ma wartości niezerowe, rozkład przestawiony na rysunku [dense2_plot]. [Rozkład w macierzy DENSE2]

[dense2_plot]

BCSSTK32 ma wymiar 44609 × 44609, z czego 0.1% jest elementami niezerowymi, rozkład przestawiony na rysunku [bcsstk32_plot] wykazuje symetryczność względem przekątnej i niskie skumulowanie względem niej. [Rozkład w macierzy BCSSTK32]

[bcsstk32_plot]

SCIRCUIT ma wymiar 170998 × 170998, z czego 0.003% jest elementami niezerowymi, rozkład przestawiony na rysunku [scircuit_plot] wykazuje symetryczność względem przekątnej i średnie skumulowanie względem niej. [Rozkład w macierzy SCIRCUIT]

[scircuit_plot]

GA41AS41H72 ma wymiar 268096 × 268096, z czego 0.026% jest elementami niezerowymi, rozkład przestawiony na rysunku [ga41as41h72_plot] wykazuje symetryczność względem przekątnej i wysokie skumulowanie względem niej. [Rozkład w macierzy GA41AS41H72]

[ga41as41h72_plot]

Analizując wykres [all_plot] zauważalna jest wysoka wydajność formatu CSR. W dwóch przypadkach jest najwyższa, natomiast w pozostałych jest blisko największej osiągniętej wydajności. Format SELL wraz ze wzrostem C osiąga wyższe wyniki, w niektórych przypadkach będąc bardziej wydajnym niż CSR, natomiast dla niektórych macierzy, gdy C stawało się większe niż 4 wydajność spadała. Wydajność formatu ELL nie wyróżniała się ponad inne formaty, pomimo znacznie większego zużycia pamięci. W ponad połowie przypadków format ten był szybszy niż COO i CSC, natomiast dla macierzy z małym zagęszczeniem lub małą ilością elementów format COO osiągał najwyższą wydajność ze wszystkich formatów. Pomimo najmniejszego zużycia pamięci format BSR osiągał wyniki zawsze gorsze od SELL i CSR, nawet dla macierzy DENSE2, która idealnie wypełnia całą macierz blokami bez elementów zerowych, poza tą macierzą wraz ze wzrostem rozmiaru bloku wydajność spadała.

[Wydajność różnych formatów macierzy]

[all_plot]

Wprowadzono pojęcie efektywności formatu, który jest sposobem porównania efektywności wykorzystania pamięci do uzyskania danego poziomu wydajności obliczeniowej, określonego przez stałą k:

$$k = \frac{1}{t \cdot s}$$

stała efektywności

czas obliczeń

rozmiar pamięci potrzebny do reprezentacji macierzy

Pozwala ona na porównanie w kontekście tej samej macierzy wydajności obliczeniowej w zależności od ilości wykorzystanej pamięci. Stała ta faworyzuje jak najmniejsze wykorzystanie pamięci i w tym samym momencie jak najszybsze wykonanie programu, format może wykorzystać więcej pamięci, jeżeli czas wykonania na tym drastycznie zyskuje. Porównywanie różnych stałych może zostać dokonane tylko w obrębie tej samej macierzy. Celem ułatwienia porównań na wykresie [all_k_plot] przedstawiono każdą wartość k przeskalowaną względem stałej k dla formatu CSR. W skutek tego w każdej macierzy format CSR zyskuje wartość k = 1, pozostałe wartości należy interpretować jako mnożnik efektywności tego formatu dla tej macierzy względem formatu CSR. Wybrano CSR ze względu na średnio najwyższe wyniki oraz stosunkowo niskie zużycie pamięci. W dwóch przypadkach macierzy, format CSR jest najbardziej efektywnym formatem, dla macierzy _DENSE2_ jest prawie dwa razy mniej efektywny niż BSR dla rozmiaru bloku równego 8, dla macierzy _BEAFLW_ jest drugi co do efektywności względem formatu COO, która jest 2.5 raza bardziej efektywna i dla BCSSTK32 jest prawie na równi z wariantami SELL i BSR.

[Porównanie efektywności wykorzystania pamięci]

[all_k_plot]

Finalne wyniki posiadały pewne różnice pomiędzy sobą, największy błąd względny pojedynczego elementu wektora wyjściowego, dla którego bazą był wynik obliczony na jednostce centralnej formatem ELL wynosił 1.894% dla formatu CSC w macierzy GA41AS41H72. Różnice te są oczekiwanym rezultatem zmiany kolejności wykonywania obliczeń, ponieważ standard IEEE-754 nie gwarantuje łączności obliczeń. Przez to należy rozumieć, iż zachodzi następująca nierówność:

(_x_ + _y_) + _z_ ≠ _x_ + (_y_ + _z_)

Połączenie formatu, który rozdziela pracę w przeciwnym kierunku co format ELL oraz atomicznej redukcji do każdego elementu wektora wyjściowego, tworzy środowisko, w którym oczekiwane będzie, iż kolejność wykonywanych operacji będzie różna od tej, która miała miejsce podczas obliczeń na jednostce centralnej. Dodatkowo, duża ilość elementów i niejednolite wartości macierzy GA41AS41H72 tylko potęgują ten efekt.

Obliczenia wymagane do wykonania operacji iloczynu macierz-wektor są proste, jedno mnożenie i jedno dodawanie dla każdego elementu macierzy, dlatego tego mikroprocesor przez większość czasu zawsze będzie czekać na pamięć potrzebną do wykonania zadanych operacji. Mierzony czas w większości algorytmów będzie jedynie czasem potrzebnym na załadowanie danej macierzy z pamięci głównej operacyjnej procesora graficznego do jego rejestrów. Przez to czynnikiem limitującym teoretyczne maksimum wydajności będzie maksymalna przepustowość pamięci głównej. Na wykresie [absolute_tput] ukazano całkowitą przepustowość jako ilość pamięci potrzebnej do reprezentacji danej macierzy podzieloną przez średni czas wykonania algorytmu. Aby określić maksymalną przepustowość pamięci procesora graficznego należy znać taktowanie pamięci, szerokość szyny pamięci i typ pamięci, który jest zainstalowany ze względu na fakt, iż różne typy mogą dostarczyć więcej niż jeden bit danych w każdym cyklu. Używając następującego równania:

_T_ = _G__f__(_m_)(_w__(_b_)/8)

teoretyczna maksymalna przepustowość pamięci

ilość bitów przesyłanych w każdym cyklu przez pamięć

taktowanie pamięci

szerokość szyny w bitach

Na podstawie tego równania określono maksymalną przepustowość pamięci na wartość równą 336GB/s, algorytmy zbliżające się do tej wartości można uznać za optymalne, ponieważ wykorzystują całą dostarczoną im pamięć bezstratnie. W budowaniu wykresu pomięto format ELL, gdyż ciężko jest określić jaka część pamięci została załadowana ze względu na fakt, iż obliczenia mogą zostać zakończone, jeżeli dane w danym rzędzie się skończyły.

[Porównanie całkowitej przepustowości pamięci]

[absolute_tput]

Na wykresie można zauważyć, że formatem najbliżej teoretycznego limitu jest SELL, gdy C = 32 dla macierzy Ga41As41H72, ten rozmiar paska równy jest rozmiarowi _warp_’u dla procesorów graficznych NVIDIA. Wzrost przepustowości wraz ze wzrostem C dla formatu SELL, można wytłumaczyć łączeniem dostępu do pamięci pomiędzy wątkami wewnątrz pojedynczego _warp_’u. Jeżeli wszystkie wątki wykonują wczytywanie z kolejno po sobie występującej pamięci, kontroler może połączyć wszystkie zapytania w jedno, co zmniejsza narzut na szynę pamięci procesora graficznego. W prawie każdym przypadku CSR posiada drugą najwyższą przepustowość pamięci po SELL, nie przekracza ona natomiast nigdy progu 50%, co wskazuje na pole do optymalizacji, którą udało się osiągnąć w praktyce. Format COO i CSC wykazują w większości najniższe przepustowości, najprawdopodobniej ze względu na kolizję w operacjach atomicznych. BSR wykazuje niską przepustowość całkowitą na pewnych macierzach natomiast wysoką na innych, format ten jest dobrym kandydatem na głębszą analizę wydajnościową przy wykorzystaniu takich narzędzi jak NVIDIA NSight.

NVIDIA NSight to zestaw narzędzi pozwalających na pracowanie z programami graficznymi, gdy uruchomione one zostaną na procesorze graficznym firmy NVIDIA. Dla _Vulkan_ istnieje możliwość zebrania danych na temat wykorzystania procesora graficznego przy użyciu _NSight Graphics_, używając opcji _GPU Trace_, ten pozwoli nam zebrać takie dane jak te w ilustracji [nsight_results]. Są to między innymi metryki odnośnie przepustowości pamięci w każdej z pamięci podręcznych, nietrafienia w pamięć podręczną, wykorzystanie rejestrów i wiele innych. Na ich podstawie możliwe jest dokonanie decyzji, które poprawi dany aspekt rozwiązania w taki sposób, aby rzecz będąca czynnikiem limitującym była zminimalizowana w najbardziej możliwy sposób.

[Metryki zebrane z uruchomienia shadera w NSight Graphics]

[nsight_results]



PODSUMOWANIE


Praca obrała za cel stworzenie programu komunikującego się z procesorem graficznym przy pomocy interfejsu Vulkan. Przy jego pomocy zaprzęgnięto procesor graficzny do wykonywania arbitralnych obliczeń, które wykorzystano do obliczenia wyników mnożenia macierzy rzadkiej z wektorem. Operację wykonano przy pomocy wielu różnych formatów przechowywania macierzy rzadkich na przykładowych macierzach rzadkich o szerokim spektrum cech charakterystycznych. Na podstawie uzyskanych wyników stwierdzono, że format CSR najczęściej będzie optymalnym lub najbliżej optymalnym formatem przechowania macierzy rzadkiej, nie tylko w kontekście czystej wydajności obliczeniowej, lecz również z perspektywy efektywności zużycia pamięci. Nietrywialna wydajność obliczeń wskazuje, iż interfejs Vulkan posiada bardzo swobodny dostęp do wykorzystania wszystkich zasobów procesora graficznego celem dokonania arbitralnych obliczeń.

Tak jak w każdej dziedzinie inżynieryjnej najlepsza decyzja to ta podjęta w odpowiednim kontekście, dla najlepszych wyników należałoby więc dokonać ewaluacji jak największej ilości formatów w przestrzeni rozwiązywanego problemu. Należy zwrócić uwagę, iż istnieją sytuacje, w których prędkość obliczeń nie gra roli, ponieważ liczy się możliwie największa kompresja macierzy rzadkiej w pamięci. Dla takich zastosowań nawet mało wydajny format BSR będzie w stanie dostarczyć najmniejszego zużycia pamięci dla niektórych macierzy rzadkich.

Temat nie został w pełni zgłębiony, perspektywą rozwoju może być przeniesienie części obliczeń w grach trójwymiarowych, wykorzystujących silną symulację fizyczną na procesor graficzny, celem jej przyśpieszenia lub wykorzystanie procesora graficznego w urządzeniu mobilnym, aby umożliwić mu lepsze reprezentowanie rozszerzonej rzeczywistości poprzez zwiększoną wydajność przetwarzania obrazów.
